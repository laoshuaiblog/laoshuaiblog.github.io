<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>浅谈Elastic Stack组件集成和应用 - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/3ea9901a69c40bd573cca9caef4c224b/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="浅谈Elastic Stack组件集成和应用">
  <meta property="og:description" content="Elasticsearch 与 Elastic Stack 组件集成和应用 Elastic Stack（以前称为 ELK Stack）是一套开源的日志管理和分析解决方案，由 Elasticsearch、Logstash、Kibana 和 Beats 四个主要组件组成。本文将详细讲解 Elasticsearch 与其他 Elastic Stack 组件的集成和应用。
Elasticsearch Elasticsearch 是 Elastic Stack 的核心组件，负责存储、搜索和分析数据。它是一个分布式搜索和分析引擎，基于 Apache Lucene 构建。Elasticsearch 提供了实时的全文搜索功能，以及复杂的数据聚合和分析功能。
Logstash Logstash 概述 Logstash 是一个数据处理管道，负责收集、处理和转发数据。它可以从多种来源（如日志文件、消息队列等）收集数据，对数据进行过滤、转换和丰富，然后将数据发送到 Elasticsearch 或其他目标系统。Logstash 支持多种输入、过滤和输出插件，可以灵活地处理各种数据格式和场景。Logstash 可以应用于多种场景，如日志分析、指标收集、事件处理等。结合 Elasticsearch 和 Kibana，用户可以快速搭建强大的数据处理和分析系统，提高运维效率和数据洞察。
Logstash 架构 Logstash 的架构主要包括三个部分：输入插件、过滤插件和输出插件。
输入插件：输入插件负责从数据源收集数据。Logstash 支持多种输入插件，如 file（用于读取文件）、tcp（用于接收 TCP 数据）、syslog（用于接收 Syslog 数据）等。用户可以根据需要选择合适的输入插件。
过滤插件：过滤插件负责对收集到的数据进行处理。Logstash 支持多种过滤插件，如 grok（用于解析日志格式）、mutate（用于修改字段）、geoip（用于将 IP 地址转换为地理位置信息）等。用户可以根据需要选择合适的过滤插件。
输出插件：输出插件负责将处理后的数据发送到目标系统。Logstash 支持多种输出插件，如 elasticsearch（用于发送数据到 Elasticsearch）、file（用于写入文件）、kafka（用于发送数据到 Kafka）等。用户可以根据需要选择合适的输出插件。
Logstash 配置 Logstash 使用配置文件来定义数据处理管道。配置文件由输入、过滤和输出三个部分组成，每个部分可以包含一个或多个插件。以下是一个简单的 Logstash 配置示例：
input { file { path =&amp;gt; &#34;">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-12-09T11:00:00+08:00">
    <meta property="article:modified_time" content="2023-12-09T11:00:00+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">浅谈Elastic Stack组件集成和应用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="Elasticsearch__Elastic_Stack__0"></a>Elasticsearch 与 Elastic Stack 组件集成和应用</h2> 
<p>Elastic Stack（以前称为 ELK Stack）是一套开源的日志管理和分析解决方案，由 Elasticsearch、Logstash、Kibana 和 Beats 四个主要组件组成。本文将详细讲解 Elasticsearch 与其他 Elastic Stack 组件的集成和应用。</p> 
<h3><a id="Elasticsearch_4"></a>Elasticsearch</h3> 
<p>Elasticsearch 是 Elastic Stack 的核心组件，负责存储、搜索和分析数据。它是一个分布式搜索和分析引擎，基于 Apache Lucene 构建。Elasticsearch 提供了实时的全文搜索功能，以及复杂的数据聚合和分析功能。</p> 
<h3><a id="Logstash_8"></a>Logstash</h3> 
<h4><a id="Logstash__9"></a>Logstash 概述</h4> 
<p>Logstash 是一个数据处理管道，负责收集、处理和转发数据。它可以从多种来源（如日志文件、消息队列等）收集数据，对数据进行过滤、转换和丰富，然后将数据发送到 Elasticsearch 或其他目标系统。Logstash 支持多种输入、过滤和输出插件，可以灵活地处理各种数据格式和场景。Logstash 可以应用于多种场景，如日志分析、指标收集、事件处理等。结合 Elasticsearch 和 Kibana，用户可以快速搭建强大的数据处理和分析系统，提高运维效率和数据洞察。</p> 
<h4><a id="Logstash__11"></a>Logstash 架构</h4> 
<p>Logstash 的架构主要包括三个部分：输入插件、过滤插件和输出插件。</p> 
<ol><li> <p><strong>输入插件</strong>：输入插件负责从数据源收集数据。Logstash 支持多种输入插件，如 file（用于读取文件）、tcp（用于接收 TCP 数据）、syslog（用于接收 Syslog 数据）等。用户可以根据需要选择合适的输入插件。</p> </li><li> <p><strong>过滤插件</strong>：过滤插件负责对收集到的数据进行处理。Logstash 支持多种过滤插件，如 grok（用于解析日志格式）、mutate（用于修改字段）、geoip（用于将 IP 地址转换为地理位置信息）等。用户可以根据需要选择合适的过滤插件。</p> </li><li> <p><strong>输出插件</strong>：输出插件负责将处理后的数据发送到目标系统。Logstash 支持多种输出插件，如 elasticsearch（用于发送数据到 Elasticsearch）、file（用于写入文件）、kafka（用于发送数据到 Kafka）等。用户可以根据需要选择合适的输出插件。</p> </li></ol> 
<h4><a id="Logstash__21"></a>Logstash 配置</h4> 
<p>Logstash 使用配置文件来定义数据处理管道。配置文件由输入、过滤和输出三个部分组成，每个部分可以包含一个或多个插件。以下是一个简单的 Logstash 配置示例：</p> 
<pre><code class="prism language-ruby">input <span class="token punctuation">{<!-- --></span>
  file <span class="token punctuation">{<!-- --></span>
    path <span class="token operator">=&gt;</span> <span class="token string-literal"><span class="token string">"/var/log/apache2/access.log"</span></span>
    start_position <span class="token operator">=&gt;</span> <span class="token string-literal"><span class="token string">"beginning"</span></span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

filter <span class="token punctuation">{<!-- --></span>
  grok <span class="token punctuation">{<!-- --></span>
    match <span class="token operator">=&gt;</span> <span class="token punctuation">{<!-- --></span> <span class="token string-literal"><span class="token string">"message"</span></span> <span class="token operator">=&gt;</span> <span class="token string-literal"><span class="token string">"%{COMBINEDAPACHELOG}"</span></span> <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
  geoip <span class="token punctuation">{<!-- --></span>
    source <span class="token operator">=&gt;</span> <span class="token string-literal"><span class="token string">"clientip"</span></span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

output <span class="token punctuation">{<!-- --></span>
  elasticsearch <span class="token punctuation">{<!-- --></span>
    hosts <span class="token operator">=&gt;</span> <span class="token punctuation">[</span><span class="token string-literal"><span class="token string">"localhost:9200"</span></span><span class="token punctuation">]</span>
    index <span class="token operator">=&gt;</span> <span class="token string-literal"><span class="token string">"apache_logs"</span></span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre> 
<p>这个配置示例定义了一个从 Apache 日志文件收集数据、解析日志格式并提取地理位置信息，然后将数据发送到 Elasticsearch 的数据处理管道。</p> 
<h4><a id="Logstash__52"></a>Logstash 应用场景</h4> 
<p>Logstash 可以应用于多种场景，如日志分析、指标收集和事件处理。以下是一些常见的应用场景：</p> 
<ol><li> <p><strong>日志分析</strong>：Logstash 可以从各种日志文件（如 Apache、Nginx、MySQL 等）收集数据，解析日志格式并提取有用的字段，然后将数据发送到 Elasticsearch 进行存储和分析。用户可以使用 Kibana 对日志数据进行可视化和分析，快速发现问题和洞察。</p> </li><li> <p><strong>指标收集</strong>：Logstash 可以从各种系统和服务（如 CPU、内存、磁盘、网络等）收集指标数据，然后将数据发送到 Elasticsearch 进行存储和分析。用户可以使用 Kibana 对指标数据进行可视化和分析，监控系统和服务的性能和健康状况。</p> </li><li> <p><strong>事件处理</strong>：Logstash 可以从各种事件源（如消息队列、数据库、API 等）收集事件数据，对数据进行过滤、转换和丰富，然后将数据发送到 Elasticsearch 或其他目标系统进行处理和分析。用户可以使用 Kibana 对事件数据进行可视化和分析，实时监控业务活动和异常情况。</p> </li><li> <p><strong>安全分析</strong>：Logstash 可以从各种安全设备（如防火墙、入侵检测系统等）收集日志和事件数据，对数据进行过滤、转换和丰富，然后将数据发送到 Elasticsearch 进行存储和分析。用户可以使用 Kibana 对安全数据进行可视化和分析，发现潜在的安全威胁和漏洞。</p> </li><li> <p><strong>网络监控</strong>：Logstash 可以从网络设备（如路由器、交换机等）收集流量和性能数据，对数据进行过滤、转换和丰富，然后将数据发送到 Elasticsearch 进行存储和分析。用户可以使用 Kibana 对网络数据进行可视化和分析，监控网络性能和故障。</p> </li></ol> 
<h3><a id="Kibana_65"></a>Kibana</h3> 
<h4><a id="Kibana__66"></a>Kibana 概述</h4> 
<p>Kibana 是一个数据可视化和管理工具，用于与 Elasticsearch 交互并展示数据。Kibana 提供了丰富的图表类型（如柱状图、折线图、饼图等），可以帮助用户快速分析和理解数据。此外，Kibana 还提供了一些管理功能，如索引管理、集群监控等。</p> 
<h4><a id="Kibana__68"></a>Kibana 功能</h4> 
<p>Kibana 的主要功能包括数据可视化、数据搜索、数据分析和集群管理。</p> 
<ol><li> <p><strong>数据可视化</strong>：Kibana 提供了丰富的图表类型，如柱状图、折线图、饼图、地图等。用户可以通过拖放字段和设置参数，快速创建和定制图表。Kibana 还支持将多个图表组合成仪表板，以便于数据展示和报告。</p> </li><li> <p><strong>数据搜索</strong>：Kibana 提供了一个搜索框，用户可以输入查询语句（支持 Lucene 查询语法和 Elasticsearch 查询 DSL）来搜索数据。Kibana 还提供了一些搜索工具，如过滤器、时间选择器等，以帮助用户精确地定位数据。</p> </li><li> <p><strong>数据分析</strong>：Kibana 提供了一些高级的数据分析功能，如数据聚合、时间序列分析、地理空间分析等。用户可以通过这些功能深入挖掘数据，发现数据的模式和趋势。</p> </li><li> <p><strong>集群管理</strong>：Kibana 提供了一些管理功能，如索引管理、集群监控、用户和角色管理等。用户可以通过这些功能管理 Elasticsearch 集群，监控集群的状态和性能。</p> </li></ol> 
<h4><a id="Kibana__80"></a>Kibana 使用方法</h4> 
<p>以下是一个使用 Kibana 创建柱状图的简单示例：</p> 
<ol><li> <p>打开 Kibana 的主页，点击左侧菜单的 “Visualize”。</p> </li><li> <p>点击 “Create a visualization”，然后选择 “Vertical Bar”。</p> </li><li> <p>选择一个索引模式，然后设置聚合参数。例如，可以设置 “X-Axis” 为 “Date Histogram”，“Y-Axis” 为 “Count”。</p> </li><li> <p>点击 “Update”，Kibana 将根据设置的参数生成柱状图。</p> </li><li> <p>如果满意的话，可以点击 “Save” 保存这个图表，以便于以后使用。</p> </li></ol> 
<h4><a id="Kibana__94"></a>Kibana 应用场景</h4> 
<p>Kibana 可以应用于多种场景，如日志分析、指标监控、业务报告等。以下是一些常见的应用场景：</p> 
<ol><li> <p><strong>日志分析</strong>：Kibana 可以对 Elasticsearch 中的日志数据进行可视化和分析。用户可以创建各种图表来展示日志的分布、趋势和异常，快速发现问题和洞察。</p> </li><li> <p><strong>指标监控</strong>：Kibana 可以对 Elasticsearch 中的指标数据进行可视化和分析。用户可以创建仪表板来展示系统和服务的性能和健康状况，实时监控运行状态。</p> </li><li> <p><strong>业务报告</strong>：Kibana 可以对 Elasticsearch 中的业务数据进行可视化和分析。用户可以创建报告来展示业务的进度、效果和问题，支持决策和优化。</p> </li></ol> 
<h3><a id="Beats_103"></a>Beats</h3> 
<h4><a id="Beats__104"></a>Beats 概述</h4> 
<p>Beats 是一系列轻量级的数据采集器，用于从各种数据源收集数据并发送到 Elasticsearch 或 Logstash。Beats 包括多个子项目，如 Filebeat（用于收集日志文件）、Metricbeat（用于收集系统和服务指标）、Packetbeat（用于收集网络数据）等。Beats 可以在数据源所在的服务器上运行，占用资源较少。</p> 
<h3><a id="Beats__107"></a>Beats 架构</h3> 
<p>Beats 的架构主要包括两个部分：数据采集器和输出插件。</p> 
<ol><li> <p><strong>数据采集器</strong>：数据采集器负责从数据源收集数据。每个 Beats 子项目都包含一个或多个数据采集器，用于收集特定类型的数据。例如，Filebeat 包含一个日志采集器，用于读取日志文件；Metricbeat 包含多个指标采集器，用于收集系统和服务指标。</p> </li><li> <p><strong>输出插件</strong>：输出插件负责将收集到的数据发送到目标系统。Beats 支持多种输出插件，如 Elasticsearch（用于发送数据到 Elasticsearch）、Logstash（用于发送数据到 Logstash）、Kafka（用于发送数据到 Kafka）等。用户可以根据需要选择合适的输出插件。</p> </li></ol> 
<h4><a id="Beats__114"></a>Beats 功能</h4> 
<p>Beats 的主要功能包括数据采集、数据处理和数据发送。</p> 
<ol><li> <p><strong>数据采集</strong>：Beats 提供了多种数据采集器，用于从各种数据源收集数据。例如，Filebeat 可以收集日志文件；Metricbeat 可以收集系统和服务指标；Packetbeat 可以收集网络数据。</p> </li><li> <p><strong>数据处理</strong>：Beats 支持对收集到的数据进行简单的处理，如解析、过滤和丰富。例如，Filebeat 支持多行解析，用于处理多行日志事件；Metricbeat 支持模块化配置，用于收集不同服务的指标。</p> </li><li> <p><strong>数据发送</strong>：Beats 支持将收集到的数据发送到 Elasticsearch 或 Logstash。用户可以选择合适的输出插件，根据需要配置输出参数。例如，可以设置 Elasticsearch 的索引名称、Logstash 的管道名称等。</p> </li></ol> 
<h4><a id="Beats__123"></a>Beats 应用场景</h4> 
<p>Beats 可以应用于多种场景，如日志收集、指标监控、网络分析等。以下是一些常见的应用场景：</p> 
<ol><li> <p><strong>日志收集</strong>：使用 Filebeat 从应用服务器上收集日志文件。Filebeat 可以监控指定的日志文件或目录，并将新增的日志事件发送到 Elasticsearch 或 Logstash。用户可以使用 Kibana 对日志数据进行可视化和分析，快速发现问题和洞察。</p> </li><li> <p><strong>指标监控</strong>：使用 Metricbeat 从系统和服务上收集指标数据。Metricbeat 支持多个模块，如 system（用于收集系统指标）、nginx（用于收集 Nginx 指标）等。用户可以使用 Kibana 对指标数据进行可视化和分析，监控系统和服务的性能和健康状况。</p> </li><li> <p><strong>网络分析</strong>：使用 Packetbeat 从网络设备上收集流量数据。Packetbeat 可以解析多种协议（如 HTTP、MySQL、DNS 等），提取有用的字段。用户可以使用 Kibana 对网络数据进行可视化和分析，监控网络性能和故障。</p> </li></ol> 
<h3><a id="_132"></a>集成和应用</h3> 
<h4><a id="Elastic_Stack__133"></a>Elastic Stack 组件协同工作</h4> 
<p>Elastic Stack 的组件可以灵活地组合和集成，以满足各种数据处理和分析需求。以下是一个典型的 Elastic Stack 应用场景：日志分析。</p> 
<ol><li> <p><strong>数据收集</strong>：使用 Beats（如 Filebeat）从应用服务器上收集日志文件。Filebeat 可以监控指定的日志文件或目录，并将新增的日志事件发送到 Logstash 或 Elasticsearch。</p> </li><li> <p><strong>数据处理</strong>：使用 Logstash 对收集到的日志数据进行处理。Logstash 可以解析日志格式（如 JSON、CSV、Grok 等），提取有用的字段，并对数据进行过滤、转换和丰富。例如，可以使用 GeoIP 插件将 IP 地址转换为地理位置信息。</p> </li><li> <p><strong>数据存储</strong>：将处理后的日志数据发送到 Elasticsearch。Elasticsearch 可以对数据进行实时索引和存储，支持全文搜索和复杂的数据聚合。</p> </li><li> <p><strong>数据可视化</strong>：使用 Kibana 对 Elasticsearch 中的日志数据进行可视化和分析。Kibana 提供了丰富的图表类型和交互式操作，可以帮助用户快速发现问题和洞察。</p> </li><li> <p><strong>告警和监控</strong>：使用 Elasticsearch 的告警功能（如 Watcher）和 Kibana 的监控功能，对系统和服务进行实时监控。当发生异常或故障时，可以通过邮件、短信等方式通知相关人员。</p> </li></ol> 
<h4><a id="_147"></a>典型应用场景</h4> 
<p>Elastic Stack 可以应用于多种场景，如日志分析、指标监控、安全分析等。以下是一些典型的应用场景：</p> 
<ol><li> <p><strong>日志分析</strong>：Elastic Stack 可以对各种日志文件（如 Apache、Nginx、MySQL 等）进行收集、处理、存储和分析。用户可以使用 Kibana 创建各种图表和仪表板，快速发现问题和洞察。</p> </li><li> <p><strong>指标监控</strong>：Elastic Stack 可以对各种系统和服务（如 CPU、内存、磁盘、网络等）进行指标收集、处理、存储和分析。用户可以使用 Kibana 创建仪表板来展示系统和服务的性能和健康状况，实时监控运行状态。</p> </li><li> <p><strong>安全分析</strong>：Elastic Stack 可以对各种安全设备（如防火墙、入侵检测系统等）进行日志和事件收集、处理、存储和分析。用户可以使用 Kibana 创建图表和仪表板，发现潜在的安全威胁和漏洞。</p> </li><li> <p><strong>网络监控</strong>：Elastic Stack 可以对网络设备（如路由器、交换机等）进行流量和性能数据收集、处理、存储和分析。用户可以使用 Kibana 创建图表和仪表板，监控网络性能和故障。</p> </li></ol> 
<h4><a id="_159"></a>部署策略</h4> 
<p>部署 Elastic Stack 时，需要考虑各个组件的资源需求、性能和可用性。以下是一些部署策略的建议：</p> 
<ol><li> <p><strong>资源分配</strong>：为 Elasticsearch、Logstash 和 Kibana 分配足够的资源，以确保良好的性能和稳定性。Elasticsearch 通常需要较多的内存和磁盘空间，以支持数据索引和存储；Logstash 需要较多的 CPU 和内存，以支持数据处理；Kibana 需要较少的资源，但应确保有足够的内存来支持大型仪表板和查询。</p> </li><li> <p><strong>集群规划</strong>：根据数据量和查询负载，规划 Elasticsearch 集群的节点数和分片数。通常情况下，可以使用多个数据节点来提高数据存储和查询能力，以及多个主节点来提高集群稳定性。此外，可以根据数据的重要性和访问频率，设置不同的副本数和分片数。</p> </li><li> <p><strong>负载均衡</strong>：使用负载均衡器（如 HAProxy、Nginx 等）来分发 Elasticsearch 和 Kibana 的请求，以提高性能和可用性。对于 Logstash，可以使用多个实例来处理不同的数据源，或者使用 Kafka 等消息队列来缓冲和分发数据。</p> </li><li> <p><strong>监控和告警</strong>：使用 Elasticsearch 和 Kibana 的监控功能，对 Elastic Stack 的各个组件进行实时监控。当发生异常或故障时，可以通过邮件、短信等方式通知相关人员。此外，可以使用第三方监控工具（如 Grafana、Prometheus 等）来监控 Elastic Stack 的性能和资源使用情况。</p> </li><li> <p><strong>备份和恢复</strong>：定期对 Elasticsearch 的数据进行备份，以防止数据丢失或损坏。可以使用 Elasticsearch 的快照功能，将数据备份到远程存储系统（如 Amazon S3、Google Cloud Storage 等）。在发生故障时，可以使用备份数据进行恢复，以确保数据的安全和可用性。</p> </li></ol> 
<h3><a id="_173"></a>小结</h3> 
<p>Elastic Stack 是一套强大的数据处理和分析解决方案，由 Elasticsearch、Logstash、Kibana 和 Beats 四个主要组件组成。通过灵活地集成和应用这些组件，用户可以快速搭建日志分析、指标监控、安全分析等系统，提高运维效率和数据洞察。在部署 Elastic Stack 时，需要考虑各个组件的资源需求、性能和可用性，以确保系统的稳定性和可扩展性。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3216eb638049e49b30f75ac5d4215e11/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">mysql存json数据时的查询办法</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/058630582ed64fdb23bce44ae79707a8/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">三着色问题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>