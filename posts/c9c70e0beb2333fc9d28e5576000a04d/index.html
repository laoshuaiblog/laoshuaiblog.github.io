<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>Polars ，最强Pandas平替？ - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/c9c70e0beb2333fc9d28e5576000a04d/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="Polars ，最强Pandas平替？">
  <meta property="og:description" content="转自：数据studio
大家好，我是阿粥～
今天给大家分享关于Polars库的内容，前排提示，文末送两本好书～
Polars是一个用于操作结构化数据的高性能DataFrame库，可以说是平替pandas最有潜质的包。Polars其核心部分是用Rust编写的，但该库也提供了Python接口。它的主要特点包括：
快速: Polars是从零开始编写的，紧密与机器结合，没有外部依赖。
I/O: 对所有常见数据存储层提供一流支持：本地、云存储和数据库。
易于使用: 以原始意图编写查询。Polars 在内部会使用其查询优化器确定执行最有效的方式。
离线处理: Polars支持通过其流式API进行离线数据转换。这使您能够处理结果，而无需同时将所有数据存储在内存中。
并行处理: Polars通过在可用的CPU核心之间分配工作负载，充分利用计算机性能，而无需额外配置。
矢量化查询引擎: Polars使用 Apache Arrow，一种列式数据格式，以矢量化方式处理查询。它使用 SIMD 来优化CPU使用。
User guide: https://pola-rs.github.io/polars/user-guide/
API reference: https://pola-rs.github.io/polars/py-polars/html/reference/io.html
介绍
Polars 的目标是提供一个闪电般快速的 DataFrame 库，具有以下特点：
利用计算机上所有可用的核心。
通过优化查询来减少不必要的工作/内存分配。
处理比可用 RAM 更大得多的数据集。
具有一致且可预测的 API。
具有严格的模式（在运行查询之前应该知道数据类型）。
Polars 是用 Rust 编写的，这使得它具有 C/C&#43;&#43; 性能，并允许它完全控制查询引擎中的性能关键部分。因此，Polars 为此付出了很大的努力：
减少冗余的复制。
高效地遍历内存缓存。
在并行性中最小化争用。
以块处理数据。
重用内存分配。
基础 Series &amp;amp; DataFrames Series 是一个一维数据结构。在一个 Series 中，所有元素都具有相同的数据类型（例如，整数、字符串）。下面的片段展示了如何创建一个简单的带有名称的 Series 对象。
import polars as pl import numpy as np s = pl.">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-03-05T22:03:52+08:00">
    <meta property="article:modified_time" content="2024-03-05T22:03:52+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">Polars ，最强Pandas平替？</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div id="js_content"> 
 <p style="text-align:center;">转自：数据studio</p> 
 <p>大家好，我是阿粥～</p> 
 <p>今天给大家分享关于Polars库的内容，<strong>前排提示，文末送两本好书～</strong></p> 
 <p>Polars是一个用于操作结构化数据的高性能DataFrame库，可以说是平替pandas最有潜质的包。Polars其核心部分是用Rust编写的，但该库也提供了Python接口。它的主要特点包括：</p> 
 <ul><li><p><strong>快速</strong>: Polars是从零开始编写的，紧密与机器结合，没有外部依赖。</p></li><li><p><strong>I/O</strong>: 对所有常见数据存储层提供一流支持：本地、云存储和数据库。</p></li><li><p><strong>易于使用</strong>: 以原始意图编写查询。Polars 在内部会使用其查询优化器确定执行最有效的方式。</p></li><li><p><strong>离线处理</strong>: Polars支持通过其流式API进行离线数据转换。这使您能够处理结果，而无需同时将所有数据存储在内存中。</p></li><li><p><strong>并行处理</strong>: Polars通过在可用的CPU核心之间分配工作负载，充分利用计算机性能，而无需额外配置。</p></li><li><p><strong>矢量化查询引擎</strong>: Polars使用 Apache Arrow，一种列式数据格式，以矢量化方式处理查询。它使用 SIMD 来优化CPU使用。</p></li></ul> 
 <p style="text-align:left;">User guide: https://pola-rs.github.io/polars/user-guide/<br>API reference: https://pola-rs.github.io/polars/py-polars/html/reference/io.html</p> 
 <p style="text-align:center;"><strong>介绍</strong></p> 
 <p>Polars 的目标是提供一个闪电般快速的 <code>DataFrame</code> 库，具有以下特点：</p> 
 <ul><li><p>利用计算机上所有可用的核心。</p></li><li><p>通过优化查询来减少不必要的工作/内存分配。</p></li><li><p>处理比可用 RAM 更大得多的数据集。</p></li><li><p>具有一致且可预测的 API。</p></li><li><p>具有严格的模式（在运行查询之前应该知道数据类型）。</p></li></ul> 
 <p>Polars 是用 Rust 编写的，这使得它具有 C/C++ 性能，并允许它完全控制查询引擎中的性能关键部分。因此，Polars 为此付出了很大的努力：</p> 
 <ul><li><p>减少冗余的复制。</p></li><li><p>高效地遍历内存缓存。</p></li><li><p>在并行性中最小化争用。</p></li><li><p>以块处理数据。</p></li><li><p>重用内存分配。</p></li></ul> 
 <h3></h3> 
 <h3><strong>基础</strong></h3> 
 <h4>Series &amp; DataFrames</h4> 
 <p>Series 是一个一维数据结构。在一个 Series 中，所有元素都具有相同的数据类型（例如，整数、字符串）。下面的片段展示了如何创建一个简单的带有名称的 Series 对象。</p> 
 <pre class="has"><code class="language-go">import polars as pl
import numpy as np

s = pl.Series("a", [1, 2, 3, 4, 5])
print(s)
s = pl.Series("a", [1, 2, 3, 4, 5])
print(s.min())
print(s.max())
s = pl.Series("a", ["polar", "bear", "arctic", "polar fox", "polar bear"])
s2 = s.str.replace("polar", "pola")
print(s2)
from datetime import date

start = date(2001, 1, 1)
stop = date(2001, 1, 9)
s = pl.date_range(start, stop, interval="2d", eager=True)
print(s.dt.day())</code></pre> 
 <p>DataFrame 是一个二维数据结构，由一个或多个 Series 支持，可以看作是对一系列（例如列表）Series的抽象。在 DataFrame 上可以执行的操作与在 SQL 查询中执行的操作非常相似。您可以进行 GROUP BY、JOIN、PIVOT，还可以定义自定义函数。</p> 
 <pre class="has"><code class="language-go">from datetime import datetime

df = pl.DataFrame(
    {
        "integer": [1, 2, 3, 4, 5],
        "date": [
            datetime(2022, 1, 1),
            datetime(2022, 1, 2),
            datetime(2022, 1, 3),
            datetime(2022, 1, 4),
            datetime(2022, 1, 5),
        ],
        "float": [4.0, 5.0, 6.0, 7.0, 8.0],
    }
)

print(df)
print(df.head(3))
print(df.describe())</code></pre> 
 <h4>Reading &amp; writing</h4> 
 <pre class="has"><code class="language-go">import polars as pl
from datetime import datetime

df = pl.DataFrame(
    {
        "integer": [1, 2, 3],
        "date": [
            datetime(2022, 1, 1),
            datetime(2022, 1, 2),
            datetime(2022, 1, 3),
        ],
        "float": [4.0, 5.0, 6.0],
    }
)

print(df)
df.write_csv("output.csv")
df_csv = pl.read_csv("output.csv")
print(df_csv)
df_csv = pl.read_csv("output.csv", try_parse_dates=True)
print(df_csv)</code></pre> 
 <h4>Expressions</h4> 
 <pre class="has"><code class="language-go">import polars as pl

# 创建一个简单的 DataFrame
data = {'column1': [1, 2, 3],
        'column2': ['a', 'b', 'c']}
df = pl.DataFrame(data)

# 使用表达式进行选择
selected_df = df.select(['column1'])

# 使用表达式进行过滤
filtered_df = df.filter(df['column1'] &gt; 1)
selected_df
filtered_df</code></pre> 
 <h3><strong>拼接</strong></h3> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "a": np.arange(0, 8),
        "b": np.random.rand(8),
        "d": [1, 2.0, np.NaN, np.NaN, 0, -5, -42, None],
    }
)

df2 = pl.DataFrame(
    {
        "x": np.arange(0, 8),
        "y": ["A", "A", "A", "B", "B", "C", "X", "X"],
    }
)
joined = df.join(df2, left_on="a", right_on="x")
print(joined)
stacked = df.hstack(df2)
print(stacked)</code></pre> 
 <h3><strong>概念</strong></h3> 
 <h4>Data types</h4> 
 <p>Polars 完全基于 Arrow 数据类型，并由 Arrow 内存数组支持。这使得数据处理在缓存效率和跨进程通信方面得到良好支持。大多数数据类型都与 Arrow 的实现完全一致，但有一些例外，如 <code>Utf8</code>（实际上是 <code>LargeUtf8</code>）、<code>Categorical</code> 和 <code>Object</code>（支持有限）等。以下是一些数据类型：</p> 
 <table><thead><tr><th>分组</th><th>类型</th><th>详细信息</th></tr></thead><tbody><tr><td>数值</td><td><code>Int8</code></td><td>8 位有符号整数。</td></tr><tr><td><br></td><td><code>Int16</code></td><td>16 位有符号整数。</td></tr><tr><td><br></td><td><code>Int32</code></td><td>32 位有符号整数。</td></tr><tr><td><br></td><td><code>Int64</code></td><td>64 位有符号整数。</td></tr><tr><td><br></td><td><code>UInt8</code></td><td>8 位无符号整数。</td></tr><tr><td><br></td><td><code>UInt16</code></td><td>16 位无符号整数。</td></tr><tr><td><br></td><td><code>UInt32</code></td><td>32 位无符号整数。</td></tr><tr><td><br></td><td><code>UInt64</code></td><td>64 位无符号整数。</td></tr><tr><td><br></td><td><code>Float32</code></td><td>32 位浮点数。</td></tr><tr><td><br></td><td><code>Float64</code></td><td>64 位浮点数。</td></tr><tr><td>嵌套</td><td><code>Struct</code></td><td>结构数组表示为 <code>Vec&lt;Series&gt;</code>，用于在单个列中打包多个/异构值。</td></tr><tr><td><br></td><td><code>List</code></td><td>列表数组包含包含列表值的子数组和一个偏移数组（在内部实际上是 Arrow 的 <code>LargeList</code>）。</td></tr><tr><td>时间</td><td><code>Date</code></td><td>日期表示，内部表示为距离 UNIX 纪元的天数，由 32 位有符号整数编码。</td></tr><tr><td><br></td><td><code>Datetime</code></td><td>日期时间表示，内部表示为距离 UNIX 纪元的微秒数，由 64 位有符号整数编码。</td></tr><tr><td><br></td><td><code>Duration</code></td><td>表示时间差的类型，内部表示为微秒。通过减去 <code>Date/Datetime</code> 创建。</td></tr><tr><td><br></td><td><code>Time</code></td><td>时间表示，内部表示为距午夜的纳秒数。</td></tr><tr><td>其他</td><td><code>Boolean</code></td><td>布尔类型，实际上是按位打包的。</td></tr><tr><td><br></td><td><code>Utf8</code></td><td>字符串数据（实际上在内部是 Arrow 的 <code>LargeUtf8</code>）。</td></tr><tr><td><br></td><td><code>Binary</code></td><td>以字节形式存储数据。</td></tr><tr><td><br></td><td><code>Object</code></td><td>有限支持的数据类型，可以是任何值。</td></tr><tr><td><br></td><td><code>Categorical</code></td><td>一组字符串的分类编码。</td></tr></tbody></table> 
 <h4>Contexts</h4> 
 <p>Polars 已经开发了自己的领域特定语言（DSL）用于数据转换。该语言非常易于使用，允许进行复杂的查询，同时保持人类可读性。该语言的两个核心组件是上下文（Contexts）和表达式（Expressions），我们将在下一部分介绍表达式。</p> 
 <p>正如名称所示，上下文指的是需要评估表达式的上下文。有三个主要的上下文 [^1^]：</p> 
 <ol><li><p>选择（Selection）: <code>df.select([..])</code>, <code>df.with_columns([..])</code></p></li><li><p>过滤（Filtering）: <code>df.filter()</code></p></li><li><p>分组/聚合（Group by / Aggregation）: <code>df.group_by(..).agg([..])</code></p></li></ol> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "nrs": [1, 2, 3, None, 5],
        "names": ["foo", "ham", "spam", "egg", None],
        "random": np.random.rand(5),
        "groups": ["A", "A", "B", "C", "B"],
    }
)
print(df)
# 基于df 进行计算，得到新的表格
out = df.select(
    pl.sum("nrs"), # nrs的和
    pl.col("names").sort(), # names排序后的结果
    pl.col("names").first().alias("first name"), # names第一个值
    (pl.mean("nrs") * 10).alias("10xnrs"), # nrs的均值 * 10
)
print(out)
# 原始df 新增列
df = df.with_columns(
    pl.sum("nrs").alias("nrs_sum"),
    pl.col("random").count().alias("count"),
)
print(df)
out = df.filter(pl.col("nrs") &gt; 2)
print(out)
out = df.group_by("groups").agg(
    pl.sum("nrs"),  # sum nrs by groups
    pl.col("random").count().alias("count"),  # count group members
    # sum random where name != null
    pl.col("random").filter(pl.col("names").is_not_null()).sum().name.suffix("_sum"),
    pl.col("names").reverse().alias("reversed names"),
)
print(out)</code></pre> 
 <h4>Lazy / eager API</h4> 
 <p>Polars支持两种操作模式：lazy（延迟）和eager（即时）。在eager API中，查询会立即执行，而在lazy API中，查询只有在“需要”时才会被评估。</p> 
 <pre class="has"><code class="language-go">!wget https://mirror.coggle.club/dataset/heart.csv
!head heart.csv
df = pl.read_csv("heart.csv")
df_small = df.filter(pl.col("age") &gt; 5)
df_agg = df_small.group_by("sex").agg(pl.col("chol").mean())
print(df_agg)
q = (
    pl.scan_csv("heart.csv")
    .filter(pl.col("age") &gt; 5)
    .group_by("sex")
    .agg(pl.col("chol").mean())
)
# 生成了计算逻辑

df = q.collect() # 真正计算
print(df)</code></pre> 
 <h4>Streaming API</h4> 
 <p>https://pola-rs.github.io/polars/user-guide/concepts/streaming/</p> 
 <p>Lazy API的另一个额外好处是它允许以流式方式执行查询。与一次性处理所有数据不同，Polars可以按批执行查询，使您能够处理大于内存的数据集。</p> 
 <pre class="has"><code class="language-go">q = (
    pl.scan_csv("heart.csv")
    .filter(pl.col("age") &gt; 5)
    .group_by("sex")
    .agg(pl.col("chol").mean())
)

df = q.collect(streaming=True)
print(df)</code></pre> 
 <h3><strong>表达式</strong></h3> 
 <h4>Basic operators</h4> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "nrs": [1, 2, 3, None, 5],
        "names": ["foo", "ham", "spam", "egg", None],
        "random": np.random.rand(5),
        "groups": ["A", "A", "B", "C", "B"],
    }
)
print(df)
df_numerical = df.select(
    (pl.col("nrs") + 5).alias("nrs + 5"),
    (pl.col("nrs") - 5).alias("nrs - 5"),
    (pl.col("nrs") * pl.col("random")).alias("nrs * random"),
    (pl.col("nrs") / pl.col("random")).alias("nrs / random"),
)
print(df_numerical)
df_logical = df.select(
    (pl.col("nrs") &gt; 1).alias("nrs &gt; 1"),
    (pl.col("random") &lt;= 0.5).alias("random &lt;= .5"),
    (pl.col("nrs") != 1).alias("nrs != 1"),
    (pl.col("nrs") == 1).alias("nrs == 1"),
    ((pl.col("random") &lt;= 0.5) &amp; (pl.col("nrs") &gt; 1)).alias("and_expr"),  # and
    ((pl.col("random") &lt;= 0.5) | (pl.col("nrs") &gt; 1)).alias("or_expr"),  # or
)
print(df_logical)</code></pre> 
 <h4>Column selections</h4> 
 <pre class="has"><code class="language-go">from datetime import date, datetime

df = pl.DataFrame(
    {
        "id": [9, 4, 2],
        "place": ["Mars", "Earth", "Saturn"],
        "date": pl.date_range(date(2022, 1, 1), date(2022, 1, 3), "1d", eager=True),
        "sales": [33.4, 2142134.1, 44.7],
        "has_people": [False, True, False],
        "logged_at": pl.datetime_range(
            datetime(2022, 12, 1), datetime(2022, 12, 1, 0, 0, 2), "1s", eager=True
        ),
    }
).with_row_count("rn")
print(df)
out = df.select(pl.col("*"))

# Is equivalent to
out = df.select(pl.all())
print(out)
out = df.select(pl.col("*").exclude("logged_at", "rn"))
print(out)
out = df.select(pl.col("date", "logged_at").dt.to_string("%Y-%h-%d"))
print(out)
out = df.select(pl.col("^.*(as|sa).*$"))
print(out)
out = df.select(pl.col(pl.Int64, pl.UInt32, pl.Boolean).n_unique())
print(out)
import polars.selectors as cs
out = df.select(cs.numeric() - cs.first())
print(out)
out = df.select(cs.contains("rn"), cs.matches(".*_.*"))
print(out)</code></pre> 
 <h4>Functions</h4> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "nrs": [1, 2, 3, None, 5],
        "names": ["foo", "ham", "spam", "egg", "spam"],
        "random": np.random.rand(5),
        "groups": ["A", "A", "B", "C", "B"],
    }
)
print(df)
df_samename = df.select(pl.col("nrs") + 5)
print(df_samename)
df_alias = df.select(
    (pl.col("nrs") + 5).alias("nrs + 5"),
    (pl.col("nrs") - 5).alias("nrs - 5"),
)
print(df_alias)
df_alias = df.select(
    pl.col("names").n_unique().alias("unique"),
    pl.approx_n_unique("names").alias("unique_approx"),
)
print(df_alias)
df_conditional = df.select(
    pl.col("nrs"),
    pl.when(pl.col("nrs") &gt; 2)
    .then(pl.lit(True))
    .otherwise(pl.lit(False))
    .alias("conditional"),
)
print(df_conditional)</code></pre> 
 <h3><strong>转换</strong></h3> 
 <p>类型转换（Casting）将列的底层 <code>DataType</code> 转换为新的数据类型。Polars 使用 Arrow 在内存中管理数据，并依赖于 Rust 实现中的计算核心 来执行转换。类型转换通过 <code>cast()</code> 方法实现。</p> 
 <p><code>cast</code> 方法包括一个 <code>strict</code> 参数，该参数确定当 Polars 遇到无法从源 <code>DataType</code> 转换为目标 <code>DataType</code> 的值时的行为。默认情况下，<code>strict=True</code>，这意味着 Polars 将引发错误，通知用户转换失败，并提供无法转换的值的详细信息。另一方面，如果 <code>strict=False</code>，无法转换为目标 <code>DataType</code> 的任何值都将悄悄地转换为 <code>null</code>。</p> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "integers": [1, 2, 3, 4, 5],
        "big_integers": [1, 10000002, 3, 10000004, 10000005],
        "floats": [4.0, 5.0, 6.0, 7.0, 8.0],
        "floats_with_decimal": [4.532, 5.5, 6.5, 7.5, 8.5],
    }
)

print(df)
out = df.select(
    pl.col("integers").cast(pl.Float32).alias("integers_as_floats"),
    pl.col("floats").cast(pl.Int32).alias("floats_as_integers"),
    pl.col("floats_with_decimal")
    .cast(pl.Int32)
    .alias("floats_with_decimal_as_integers"),
)
print(out)
out = df.select(
    pl.col("integers").cast(pl.Int16).alias("integers_smallfootprint"),
    pl.col("floats").cast(pl.Float32).alias("floats_smallfootprint"),
)
print(out)
df = pl.DataFrame(
    {
        "integers": [1, 2, 3, 4, 5],
        "float": [4.0, 5.03, 6.0, 7.0, 8.0],
        "floats_as_string": ["4.0", "5.0", "6.0", "7.0", "8.0"],
    }
)

out = df.select(
    pl.col("integers").cast(pl.Utf8),
    pl.col("float").cast(pl.Utf8),
    pl.col("floats_as_string").cast(pl.Float64),
)
print(out)
df = pl.DataFrame(
    {
        "integers": [-1, 0, 2, 3, 4],
        "floats": [0.0, 1.0, 2.0, 3.0, 4.0],
        "bools": [True, False, True, False, True],
    }
)

out = df.select(pl.col("integers").cast(pl.Boolean), pl.col("floats").cast(pl.Boolean))
print(out)
from datetime import date, datetime

df = pl.DataFrame(
    {
        "date": pl.date_range(date(2022, 1, 1), date(2022, 1, 5), eager=True),
        "datetime": pl.datetime_range(
            datetime(2022, 1, 1), datetime(2022, 1, 5), eager=True
        ),
    }
)

out = df.select(pl.col("date").cast(pl.Int64), pl.col("datetime").cast(pl.Int64))
print(out)</code></pre> 
 <h4>Strings</h4> 
 <pre class="has"><code class="language-go">df = pl.DataFrame({"animal": ["Crab", "cat and dog", "rab$bit", None]})

out = df.select(
    pl.col("animal").str.len_bytes().alias("byte_count"),
    pl.col("animal").str.len_chars().alias("letter_count"),
)
print(out)
out = df.select(
    pl.col("animal"),
    pl.col("animal").str.contains("cat|bit").alias("regex"),
    pl.col("animal").str.contains("rab$", literal=True).alias("literal"),
    pl.col("animal").str.starts_with("rab").alias("starts_with"),
    pl.col("animal").str.ends_with("dog").alias("ends_with"),
)
print(out)</code></pre> 
 <h4>Aggregation</h4> 
 <p>https://pola-rs.github.io/polars/user-guide/expressions/aggregation/</p> 
 <pre class="has"><code class="language-go">df = pl.read_csv("heart.csv")
print(df)
q = (
    df.lazy()
    .group_by("sex")
    .agg(
        pl.count(),
        pl.col("cp"),
        pl.first("caa"),
    )
    .sort("count", descending=True)
    .limit(5)
)

df = q.collect()
print(df)
q = (
    df.lazy()
    .group_by("sex")
    .agg(
        (pl.col("cp") == 1).sum().alias("anti"),
        (pl.col("cp") == 2).sum().alias("pro"),
    )
    .sort("pro", descending=True)
    .limit(5)
)

df = q.collect()
print(df)</code></pre> 
 <h3><strong>缺失值</strong></h3> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "value": [1, None],
    },
)
print(df)
null_count_df = df.null_count()
print(null_count_df)
df = pl.DataFrame(
    {
        "col1": [1, 2, 3],
        "col2": [1, None, 3],
    },
)
print(df)
fill_literal_df = df.with_columns(
    pl.col("col2").fill_null(pl.lit(2)),
)
print(fill_literal_df)
fill_forward_df = df.with_columns(
    pl.col("col2").fill_null(strategy="forward"),
)
print(fill_forward_df)
fill_median_df = df.with_columns(
    pl.col("col2").fill_null(pl.median("col2")),
)
print(fill_median_df)
fill_interpolation_df = df.with_columns(
    pl.col("col2").interpolate(),
)
print(fill_interpolation_df)</code></pre> 
 <h4>Window functions</h4> 
 <p style="text-align:left;">https://pola-rs.github.io/polars/user-guide/expressions/window/</p> 
 <pre class="has"><code class="language-go">!wget https://cdn.coggle.club/Pokemon.csv
!head Pokemon.csv
# then let's load some csv data with information about pokemon
df = pl.read_csv("Pokemon.csv")
print(df.head())
out = df.select(
    "Type 1",
    "Type 2",
    pl.col("Attack").mean().over("Type 1").alias("avg_attack_by_type"),
    pl.col("Defense")
    .mean()
    .over(["Type 1", "Type 2"])
    .alias("avg_defense_by_type_combination"),
    pl.col("Attack").mean().alias("avg_attack"),
)
print(out)
filtered = df.filter(pl.col("Type 2") == "Psychic").select(
    "Name",
    "Type 1",
    "Speed",
)
print(filtered)
out = filtered.with_columns(
    pl.col(["Name", "Speed"]).sort_by("Speed", descending=True).over("Type 1"),
)
print(out)</code></pre> 
 <h4>Lists and Arrays</h4> 
 <pre class="has"><code class="language-go">weather = pl.DataFrame(
    {
        "station": ["Station " + str(x) for x in range(1, 6)],
        "temperatures": [
            "20 5 5 E1 7 13 19 9 6 20",
            "18 8 16 11 23 E2 8 E2 E2 E2 90 70 40",
            "19 24 E9 16 6 12 10 22",
            "E2 E0 15 7 8 10 E1 24 17 13 6",
            "14 8 E0 16 22 24 E1",
        ],
    }
)
print(weather)
out = weather.with_columns(pl.col("temperatures").str.split(" "))
print(out)
out = weather.with_columns(pl.col("temperatures").str.split(" ")).explode(
    "temperatures"
)
print(out)
out = weather.with_columns(pl.col("temperatures").str.split(" ")).with_columns(
    pl.col("temperatures").list.head(3).alias("top3"),
    pl.col("temperatures").list.slice(-3, 3).alias("bottom_3"),
    pl.col("temperatures").list.len().alias("obs"),
)
print(out)</code></pre> 
 <h3><strong>变形</strong></h3> 
 <h4>Joins</h4> 
 <table><thead><tr><th>策略</th><th>描述</th></tr></thead><tbody><tr><td><code>inner</code></td><td>返回两个数据框中具有匹配键的行。左框或右框中的非匹配行将被丢弃。</td></tr><tr><td><code>left</code></td><td>返回左数据框中的所有行，无论是否在右数据框中找到匹配项。非匹配行的右列将被填充为null。</td></tr><tr><td><code>outer</code></td><td>返回左右两个数据框中的所有行。如果在一个框中找不到匹配项，则从另一个框中的列将被填充为null。</td></tr><tr><td><code>cross</code></td><td>返回左框中的所有行与右框中的所有行的笛卡尔积。重复的行将被保留；左框与右框的交叉连接的表长度始终为<code>len(A) × len(B)</code>。</td></tr><tr><td><code>asof</code></td><td>在此连接中，匹配是根据<em>最近</em>的键而不是相等的键执行的左连接。</td></tr><tr><td><code>semi</code></td><td>返回左框中具有与右框中相同的连接键的所有行。</td></tr><tr><td><code>anti</code></td><td>返回左框中连接键<em>不</em>在右框中出现的所有行。</td></tr></tbody></table> 
 <pre class="has"><code class="language-go">df_customers = pl.DataFrame(
    {
        "customer_id": [1, 2, 3],
        "name": ["Alice", "Bob", "Charlie"],
    }
)
print(df_customers)
df_orders = pl.DataFrame(
    {
        "order_id": ["a", "b", "c"],
        "customer_id": [1, 2, 2],
        "amount": [100, 200, 300],
    }
)
print(df_orders)
df = df_customers.join(df_orders, on="customer_id", how="inner")
print(df)

df = df_customers.join(df_orders, on="customer_id", how="left")
print(df)

df = df_customers.join(df_orders, on="customer_id", how="outer")
print(df)

df = df_customers.join(df_orders, on="customer_id", how="cross")
print(df)
df_cars = pl.DataFrame(
    {
        "id": ["a", "b", "c"],
        "make": ["ford", "toyota", "bmw"],
    }
)
print(df_cars)
df_repairs = pl.DataFrame(
    {
        "id": ["c", "c"],
        "cost": [100, 200],
    }
)
print(df_repairs)
df = df_cars.join(df_repairs, on="id", how="inner")
print(df)

df = df_cars.join(df_repairs, on="id", how="semi")
print(df)

df = df_cars.join(df_repairs, on="id", how="anti")
print(df)
df_trades = pl.DataFrame(
    {
        "time": [
            datetime(2020, 1, 1, 9, 1, 0),
            datetime(2020, 1, 1, 9, 1, 0),
            datetime(2020, 1, 1, 9, 3, 0),
            datetime(2020, 1, 1, 9, 6, 0),
        ],
        "stock": ["A", "B", "B", "C"],
        "trade": [101, 299, 301, 500],
    }
)
print(df_trades)

df_quotes = pl.DataFrame(
    {
        "time": [
            datetime(2020, 1, 1, 9, 0, 0),
            datetime(2020, 1, 1, 9, 2, 0),
            datetime(2020, 1, 1, 9, 4, 0),
            datetime(2020, 1, 1, 9, 6, 0),
        ],
        "stock": ["A", "B", "C", "A"],
        "quote": [100, 300, 501, 102],
    }
)

print(df_quotes)
df_asof_join = df_trades.join_asof(df_quotes, on="time", by="stock")
print(df_asof_join)
df_asof_tolerance_join = df_trades.join_asof(
    df_quotes, on="time", by="stock", tolerance="1m"
)
print(df_asof_tolerance_join)</code></pre> 
 <h4>Concatenation</h4> 
 <pre class="has"><code class="language-go">df_v1 = pl.DataFrame(
    {
        "a": [1],
        "b": [3],
    }
)
df_v2 = pl.DataFrame(
    {
        "a": [2],
        "b": [4],
    }
)
df_vertical_concat = pl.concat(
    [
        df_v1,
        df_v2,
    ],
    how="vertical",
)
print(df_vertical_concat)
df_h1 = pl.DataFrame(
    {
        "l1": [1, 2],
        "l2": [3, 4],
    }
)
df_h2 = pl.DataFrame(
    {
        "r1": [5, 6],
        "r2": [7, 8],
        "r3": [9, 10],
    }
)
df_horizontal_concat = pl.concat(
    [
        df_h1,
        df_h2,
    ],
    how="horizontal",
)
print(df_horizontal_concat)</code></pre> 
 <h4>Pivots</h4> 
 <pre class="has"><code class="language-go">df = pl.DataFrame(
    {
        "foo": ["A", "A", "B", "B", "C"],
        "N": [1, 2, 2, 4, 2],
        "bar": ["k", "l", "m", "n", "o"],
    }
)
print(df)
out = df.pivot(index="foo", columns="bar", values="N", aggregate_function="first")
print(out)
q = (
    df.lazy()
    .collect()
    .pivot(index="foo", columns="bar", values="N", aggregate_function="first")
    .lazy()
)
out = q.collect()
print(out)</code></pre> 
 <h4>Melts</h4> 
 <pre class="has"><code class="language-go">import polars as pl

df = pl.DataFrame(
    {
        "A": ["a", "b", "a"],
        "B": [1, 3, 5],
        "C": [10, 11, 12],
        "D": [2, 4, 6],
    }
)
print(df)
out = df.melt(id_vars=["A", "B"], value_vars=["C", "D"])
print(out)</code></pre> 
 <p><strong>最后的最后，粉丝福利，送两本北京大学出版社的</strong><strong>《码上行动：用ChatGPT学会P</strong><strong>ython编程</strong><strong>》</strong>。这本书创新地以ChatGPT作为辅助学习工具，系统全面地讲解了零基础读者如何快速有效地学习Python编程技能。内容涵盖Python入门阶段所涉及的基本语法和常见用法，学完这本书便可入门Python。示例丰富，理论与实践相结合，读者通过示例代码更容易理解概念并运用到实际开发中，值得一看！</p> 
 <p style="text-align:center;"><img src="https://images2.imgbox.com/3f/4e/IlkRXJjF_o.jpg" alt="2944a5aad00d8178c350b204e5b6080e.jpeg"></p> 
 <p style="text-align:left;"><strong>这次抽奖形式丰富点，</strong><strong>本文三连（点赞、在看或者转发任意都可）后：</strong></p> 
 <p style="text-align:left;"><strong>1、留言点赞排名第一的送一本（刷赞取消资格）</strong></p> 
 <p style="text-align:left;"><strong>2、加我微信好友，回复“抽奖”，抽奖送1本</strong></p> 
 <pre class="has"><code class="language-go">👇扫码加我好友👇</code></pre> 
 <p style="text-align:left;"><strong>3月8日22:00开奖（一个人最多只能获得一本），<strong>祝大家好运~</strong></strong></p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/3b2a243f939d496f4ec57a2b231e4d27/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">嵌入式 Linux 下的 LVGL 移植</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/2a065d9a08c616a0dae947b0a304f704/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">清除注册表的U盘(USB盘)使用记录，或者电脑的U盘记录</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>