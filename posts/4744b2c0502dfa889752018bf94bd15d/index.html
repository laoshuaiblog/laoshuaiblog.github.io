<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>智能运维中应用大语言模型的一些思考 - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/4744b2c0502dfa889752018bf94bd15d/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="智能运维中应用大语言模型的一些思考">
  <meta property="og:description" content="这个周末很忙乱，儿子高考要报综合评价，以前听报考过南科大综评的朋友说报名很简单几分钟搞定，所以也没太当回事。月底要截至，所以周末要弄好。没想到高招网的填写十分复杂，很多教委综评网站上🈶的数据都要抄下来重新填写，所以也挺折腾人的。国家的大数据战略实施了这些年了，教育部门做得还是不咋样啊。
另外一件事就是总结一下近期利用大语言模型在智能化运维领域的探索，为下一步正式开展工作理理思路。前阵子对PTUNING的训练样本，超参等都做了一些尝试，对效果也做了初步评估，不过还是没有达到我想要的效果。其中的客观原因是设备太差，很多想做的尝试因为设备原因无法更深入开展，不过最主要的原因还是对大语言模型的工作原理缺乏认知，因此只能依靠盲人摸象的方式探索，效率太低。
最近尝试了一个新的开源项目DB-GPT，这个结合了VICNUA-13B，AUTOGPT，FSCHAT，AUTOPROMPT，LANGCHAIN等技术的开源项目还是挺值得关注的，虽然目前还只是项目的初期阶段，不过最近更新的第二个版本从功能框架上已经有模有样了。最主要的是该项目完全满足离线私有化部署的要求，而且在一块24G显存的单卡上就能跑起来。对于智能化运维，本地部署，低成本是十分关键的。
通过最近的一顿折腾，对大语言模型在AIOPS中能做什么，不能做什么有些了解了，这也为下一步尽快搞出能落地的应用十分关键。最初的时候我觉得LLM只需要有基本都推理能力，通过添加PTUNE的前置模型中的专业领域知识就能很好的完成专有领域都工作了。经过这段时间点尝试，我发现基础模型的能力也十分关键，基础模型不好，会把整个工作都带歪了。利用现有开源模型，加入大量专业领域知识做FINETUNE，形成一个较好的基础模型可能对整个工程有较大的帮助。
目前国产开源的CHATGLM-6B，MOSS等都是可以本地化部署的模型。国外的羊驼现在也很热，很多人都基于这个模型加入一些中文语料，训练出效果不错的模型。META的LLAMA也是相当不错的选择，实际上很多开源模型的底子都是LLAMA。LLAMA有从7B，13B起步的多个版本，总有一款适合你。目前大热的Vicnua-13b就是基于LLAMA的。有私有化训练硬件环境的企业完全可以利用LLAMA训练出比较适合自己的模型的。
通过LANGCHAIN快速构建外挂的本地知识库是一条实现成本较低的路线，结合AUTOPROMPT，可以利用训练好的基础模型来完成复杂的工作任务，不过这方面也是有局限性的，基础模型不行，知识库的应用效果就不行。
另外要说的是设备，玩大语言模型装备很重要，没有装备很多工作无法开展，或者做起来很累。因此做之前一定要考虑好这些问题，说实在的，这些都是钱堆起来的。
在这个领域，我们目前也刚刚开始探索，如果有朋友对这方面有兴趣，希望留言探讨，看看能不能找到一条能走的通的路径。">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-09-19T17:16:51+08:00">
    <meta property="article:modified_time" content="2023-09-19T17:16:51+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">智能运维中应用大语言模型的一些思考</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p>  这个周末很忙乱，儿子高考要报综合评价，以前听报考过南科大综评的朋友说报名很简单几分钟搞定，所以也没太当回事。月底要截至，所以周末要弄好。没想到高招网的填写十分复杂，很多教委综评网站上🈶的数据都要抄下来重新填写，所以也挺折腾人的。国家的大数据战略实施了这些年了，教育部门做得还是不咋样啊。</p> 
<p>    另外一件事就是总结一下近期利用大语言模型在智能化运维领域的探索，为下一步正式开展工作理理思路。前阵子对PTUNING的训练样本，超参等都做了一些尝试，对效果也做了初步评估，不过还是没有达到我想要的效果。其中的客观原因是设备太差，很多想做的尝试因为设备原因无法更深入开展，不过最主要的原因还是对大语言模型的工作原理缺乏认知，因此只能依靠盲人摸象的方式探索，效率太低。</p> 
<p>  最近尝试了一个新的开源项目DB-GPT，这个结合了VICNUA-13B，AUTOGPT，FSCHAT，AUTOPROMPT，LANGCHAIN等技术的开源项目还是挺值得关注的，虽然目前还只是项目的初期阶段，不过最近更新的第二个版本从功能框架上已经有模有样了。最主要的是该项目完全满足离线私有化部署的要求，而且在一块24G显存的单卡上就能跑起来。对于智能化运维，本地部署，低成本是十分关键的。</p> 
<p>  通过最近的一顿折腾，对大语言模型在AIOPS中能做什么，不能做什么有些了解了，这也为下一步尽快搞出能落地的应用十分关键。最初的时候我觉得LLM只需要有基本都推理能力，通过添加PTUNE的前置模型中的专业领域知识就能很好的完成专有领域都工作了。经过这段时间点尝试，我发现基础模型的能力也十分关键，基础模型不好，会把整个工作都带歪了。利用现有开源模型，加入大量专业领域知识做FINETUNE，形成一个较好的基础模型可能对整个工程有较大的帮助。</p> 
<p>  目前国产开源的CHATGLM-6B，MOSS等都是可以本地化部署的模型。国外的羊驼现在也很热，很多人都基于这个模型加入一些中文语料，训练出效果不错的模型。META的LLAMA也是相当不错的选择，实际上很多开源模型的底子都是LLAMA。LLAMA有从7B，13B起步的多个版本，总有一款适合你。目前大热的Vicnua-13b就是基于LLAMA的。有私有化训练硬件环境的企业完全可以利用LLAMA训练出比较适合自己的模型的。</p> 
<p>  通过LANGCHAIN快速构建外挂的本地知识库是一条实现成本较低的路线，结合AUTOPROMPT，可以利用训练好的基础模型来完成复杂的工作任务，不过这方面也是有局限性的，基础模型不行，知识库的应用效果就不行。</p> 
<p>  另外要说的是设备，玩大语言模型装备很重要，没有装备很多工作无法开展，或者做起来很累。因此做之前一定要考虑好这些问题，说实在的，这些都是钱堆起来的。</p> 
<p>  在这个领域，我们目前也刚刚开始探索，如果有朋友对这方面有兴趣，希望留言探讨，看看能不能找到一条能走的通的路径。</p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/0e0252dfa22c2b1ebd10ed39a9e2e4f6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">vue-element-admin项目部署 nginx动态代理 含Docker部署、 Jenkins构建</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/27f037b8881237364635ef7a75e802eb/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">DBAIops社区版新版本发布说明</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>