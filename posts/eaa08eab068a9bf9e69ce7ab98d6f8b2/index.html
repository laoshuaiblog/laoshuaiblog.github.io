<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>SIFT（尺度不变特征变换）原理与简单应用 - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/eaa08eab068a9bf9e69ce7ab98d6f8b2/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="SIFT（尺度不变特征变换）原理与简单应用">
  <meta property="og:description" content="目录
1、SIFT（Scale Invariant Feature Transform）简介 1.1、SIFT算法的操作步骤
兴趣点的检测：
特征方向的赋值：
特征点描述：
1.2、SIFT算法的适用范围
2、尺度空间
2.1、传统图像金字塔
2.2、高斯金字塔
2.3、高斯模糊
3.DOG空间极值检测
4.删除边缘响应点
二、SIFT算法的简单应用与和Harris角点匹配的对比
1.Harris特征匹配处理
2.Harris算法在图像间寻找对应点
3.SIFT算法检测与Harris角点检测对比
4.SIFT算法匹配
未完待续。。。（代码跑得有点慢）
一、SIFT原理及简介
1、SIFT（Scale Invariant Feature Transform）简介 传统的图像匹配算法一般是利用图像的角点与边缘进行匹配，鲁棒性较差，在光照变换，角度变换的时候容易出现误差。
SIFT（尺度不变特征变换）算法是有David G.Lowe教授在1999年提出，2004年加以完善。SIFT算法在光照不同，角度不同，尺度不同的情况下应用良好。
1.1、SIFT算法的操作步骤 兴趣点的检测： 在尺度空间（第二节有详细介绍）上，利用高斯微分函数，识别尺度和旋转不变的兴趣点。
特征方向的赋值： 基于特征点的梯度方向，给特征点分配8个方向，选取主方向，与辅方向（在直方图里等于主方向80%）
特征点描述： 把特征点的梯度方向转换成特定表示。
1.2、SIFT算法的适用范围 1.目标图像的旋转，平移，尺度变换。
2.反光图像
3.目标有障碍物
2、尺度空间 在不同的尺度下的同一物体计算机不会认为是同一物体，因此，需要将物体的不同尺度提供给计算机。
2.1、传统图像金字塔 传统的图像金字塔是对图像进行简单的缩放，放大等操作。这种做法简单粗暴，但容易造成采样信息的丢失，降低匹配结果的精确度。
2.2、高斯金字塔 1.对图像做高斯平滑
2.对平滑后得图像做采样
2.3、高斯模糊 高斯模糊的目的是为了拟合人类视觉中对远近不同图像所产生的尺度差异与清晰度差异。
经过高斯模糊的图像会体现出总体模糊化，边缘清晰化的特征
高斯模糊的具体做法是：
L(x,y,σ)=G(x,y,σ)∗I(x,y)
L(x,y,σ)=G(x,y,σ)∗I(x,y)
其中，GG是高斯函数：
G(x,y,σ)=12πσ2ex2&#43;y22σ2
G(x,y,σ)=12πσ2ex2&#43;y22σ2
其中，σσ是尺度空间因子，是高斯正态分布的标准差，反映了图像被模糊的程度，其值越大图像越模糊，对应的尺度也就越大，L(x,y,σ)L(x,y,σ)对应高斯尺度空间。
--------------------- 作者：呆呆的猫 来源：CSDN 原文：https://blog.csdn.net/jiaoyangwm/article/details/79986729 3.DOG空间极值检测 DOG层是由两个相邻的高斯空间图像层相减得到的，其目的是简化计算复杂度。
4.删除边缘响应点 一些噪声点会产生边缘响应，会影响匹配结果。可以通过尺度空间DoG函数进行曲线拟合寻找极值点，去除边缘响应点。
二、SIFT算法的简单应用与和Harris角点匹配的对比 这次采用的实验原图片是集美大学的中山纪念馆。
首先我们任意选取两张图片分别进行Harris特征匹配处理与SIFT特征匹配处理的对比">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2019-03-18T00:16:31+08:00">
    <meta property="article:modified_time" content="2019-03-18T00:16:31+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">SIFT（尺度不变特征变换）原理与简单应用</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <p id="main-toc"><strong>目录</strong></p> 
<p id="1%E3%80%81SIFT%EF%BC%88Scale%20Invariant%20Feature%20Transform%EF%BC%89%E7%AE%80%E4%BB%8B%C2%A0%C2%A0-toc" style="margin-left:40px;"><a href="#1%E3%80%81SIFT%EF%BC%88Scale%20Invariant%20Feature%20Transform%EF%BC%89%E7%AE%80%E4%BB%8B%C2%A0%C2%A0" rel="nofollow">1、SIFT（Scale Invariant Feature Transform）简介  </a></p> 
<p id="1.1%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4-toc" style="margin-left:80px;"><a href="#1.1%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4" rel="nofollow">1.1、SIFT算法的操作步骤</a></p> 
<p id="%E5%85%B4%E8%B6%A3%E7%82%B9%E7%9A%84%E6%A3%80%E6%B5%8B%EF%BC%9A-toc" style="margin-left:80px;"><a href="#%E5%85%B4%E8%B6%A3%E7%82%B9%E7%9A%84%E6%A3%80%E6%B5%8B%EF%BC%9A" rel="nofollow">兴趣点的检测：</a></p> 
<p id="%E7%89%B9%E5%BE%81%E6%96%B9%E5%90%91%E7%9A%84%E8%B5%8B%E5%80%BC%EF%BC%9A-toc" style="margin-left:80px;"><a href="#%E7%89%B9%E5%BE%81%E6%96%B9%E5%90%91%E7%9A%84%E8%B5%8B%E5%80%BC%EF%BC%9A" rel="nofollow">特征方向的赋值：</a></p> 
<p id="%E7%89%B9%E5%BE%81%E7%82%B9%E6%8F%8F%E8%BF%B0%EF%BC%9A-toc" style="margin-left:80px;"><a href="#%E7%89%B9%E5%BE%81%E7%82%B9%E6%8F%8F%E8%BF%B0%EF%BC%9A" rel="nofollow">特征点描述：</a></p> 
<p id="1.2%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%82%E7%94%A8%E8%8C%83%E5%9B%B4-toc" style="margin-left:80px;"><a href="#1.2%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%82%E7%94%A8%E8%8C%83%E5%9B%B4" rel="nofollow">1.2、SIFT算法的适用范围</a></p> 
<p id="2%E3%80%81%E5%B0%BA%E5%BA%A6%E7%A9%BA%E9%97%B4-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E5%B0%BA%E5%BA%A6%E7%A9%BA%E9%97%B4" rel="nofollow">2、尺度空间</a></p> 
<p id="2.1%E3%80%81%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94-toc" style="margin-left:80px;"><a href="#2.1%E3%80%81%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94" rel="nofollow">2.1、传统图像金字塔</a></p> 
<p id="2.2%E3%80%81%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94-toc" style="margin-left:80px;"><a href="#2.2%E3%80%81%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94" rel="nofollow">2.2、高斯金字塔</a></p> 
<p id="2.3%E3%80%81%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A-toc" style="margin-left:80px;"><a href="#2.3%E3%80%81%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A" rel="nofollow">2.3、高斯模糊</a></p> 
<p id="%C2%A0%203.DOG%E7%A9%BA%E9%97%B4%E6%9E%81%E5%80%BC%E6%A3%80%E6%B5%8B-toc" style="margin-left:80px;"><a href="#%C2%A0%203.DOG%E7%A9%BA%E9%97%B4%E6%9E%81%E5%80%BC%E6%A3%80%E6%B5%8B" rel="nofollow">  3.DOG空间极值检测</a></p> 
<p id="%C2%A04.%E5%88%A0%E9%99%A4%E8%BE%B9%E7%BC%98%E5%93%8D%E5%BA%94%E7%82%B9-toc" style="margin-left:80px;"><a href="#%C2%A04.%E5%88%A0%E9%99%A4%E8%BE%B9%E7%BC%98%E5%93%8D%E5%BA%94%E7%82%B9" rel="nofollow"> 4.删除边缘响应点</a></p> 
<p id="%E4%BA%8C%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%E4%B8%8E%E5%92%8CHarris%E8%A7%92%E7%82%B9%E5%8C%B9%E9%85%8D%E7%9A%84%E5%AF%B9%E6%AF%94-toc" style="margin-left:0px;"><a href="#%E4%BA%8C%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%E4%B8%8E%E5%92%8CHarris%E8%A7%92%E7%82%B9%E5%8C%B9%E9%85%8D%E7%9A%84%E5%AF%B9%E6%AF%94" rel="nofollow">二、SIFT算法的简单应用与和Harris角点匹配的对比</a></p> 
<p id="1.Harris%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#1.Harris%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E5%A4%84%E7%90%86" rel="nofollow">1.Harris特征匹配处理</a></p> 
<p id="2.Harris%E7%AE%97%E6%B3%95%E5%9C%A8%E5%9B%BE%E5%83%8F%E9%97%B4%E5%AF%BB%E6%89%BE%E5%AF%B9%E5%BA%94%E7%82%B9-toc" style="margin-left:40px;"><a href="#2.Harris%E7%AE%97%E6%B3%95%E5%9C%A8%E5%9B%BE%E5%83%8F%E9%97%B4%E5%AF%BB%E6%89%BE%E5%AF%B9%E5%BA%94%E7%82%B9" rel="nofollow">2.Harris算法在图像间寻找对应点</a></p> 
<p id="3.SIFT%E7%AE%97%E6%B3%95%E6%A3%80%E6%B5%8B%E4%B8%8EHarris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%AF%94-toc" style="margin-left:40px;"><a href="#3.SIFT%E7%AE%97%E6%B3%95%E6%A3%80%E6%B5%8B%E4%B8%8EHarris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%AF%94" rel="nofollow">3.SIFT算法检测与Harris角点检测对比</a></p> 
<p id="4.SIFT%E7%AE%97%E6%B3%95%E5%8C%B9%E9%85%8D-toc" style="margin-left:40px;"><a href="#4.SIFT%E7%AE%97%E6%B3%95%E5%8C%B9%E9%85%8D" rel="nofollow">4.SIFT算法匹配</a></p> 
<p id="%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD%E3%80%82%E3%80%82%E3%80%82%EF%BC%88%E4%BB%A3%E7%A0%81%E8%B7%91%E5%BE%97%E6%9C%89%E7%82%B9%E6%85%A2%EF%BC%89-toc" style="margin-left:0px;"><a href="#%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD%E3%80%82%E3%80%82%E3%80%82%EF%BC%88%E4%BB%A3%E7%A0%81%E8%B7%91%E5%BE%97%E6%9C%89%E7%82%B9%E6%85%A2%EF%BC%89" rel="nofollow">未完待续。。。（代码跑得有点慢）</a></p> 
<p id="-toc" style="margin-left:0px;"> </p> 
<hr id="hr-toc"> 
<p>一、SIFT原理及简介</p> 
<h3 id="1%E3%80%81SIFT%EF%BC%88Scale%20Invariant%20Feature%20Transform%EF%BC%89%E7%AE%80%E4%BB%8B%C2%A0%C2%A0">1、SIFT（Scale Invariant Feature Transform）简介  </h3> 
<p>  传统的图像匹配算法一般是利用图像的角点与边缘进行匹配，鲁棒性较差，在光照变换，角度变换的时候容易出现误差。</p> 
<p>  SIFT（尺度不变特征变换）算法是有David G.Lowe教授在1999年提出，2004年加以完善。SIFT算法在光照不同，角度不同，尺度不同的情况下应用良好。</p> 
<h4 id="1.1%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E6%93%8D%E4%BD%9C%E6%AD%A5%E9%AA%A4">1.1、SIFT算法的操作步骤</h4> 
<h4 id="%E5%85%B4%E8%B6%A3%E7%82%B9%E7%9A%84%E6%A3%80%E6%B5%8B%EF%BC%9A">兴趣点的检测：</h4> 
<p>  在尺度空间（第二节有详细介绍）上，利用高斯微分函数，识别尺度和旋转不变的兴趣点。</p> 
<h4 id="%E7%89%B9%E5%BE%81%E6%96%B9%E5%90%91%E7%9A%84%E8%B5%8B%E5%80%BC%EF%BC%9A">特征方向的赋值：</h4> 
<p>  基于特征点的梯度方向，给特征点分配8个方向，选取主方向，与辅方向（在直方图里等于主方向80%）</p> 
<h4 id="%E7%89%B9%E5%BE%81%E7%82%B9%E6%8F%8F%E8%BF%B0%EF%BC%9A">特征点描述：</h4> 
<p>  把特征点的梯度方向转换成特定表示。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/c0/f3/8nEFeEnf_o.png"></p> 
<h4 id="1.2%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E9%80%82%E7%94%A8%E8%8C%83%E5%9B%B4">1.2、SIFT算法的适用范围</h4> 
<p>  1.目标图像的旋转，平移，尺度变换。</p> 
<p>  2.反光图像</p> 
<p>  3.目标有障碍物</p> 
<h3 id="2%E3%80%81%E5%B0%BA%E5%BA%A6%E7%A9%BA%E9%97%B4">2、尺度空间</h3> 
<p>  在不同的尺度下的同一物体计算机不会认为是同一物体，因此，需要将物体的不同尺度提供给计算机。</p> 
<h4 id="2.1%E3%80%81%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E9%87%91%E5%AD%97%E5%A1%94">2.1、传统图像金字塔</h4> 
<p>  传统的图像金字塔是对图像进行简单的缩放，放大等操作。这种做法简单粗暴，但容易造成采样信息的丢失，降低匹配结果的精确度。</p> 
<h4 id="2.2%E3%80%81%E9%AB%98%E6%96%AF%E9%87%91%E5%AD%97%E5%A1%94">2.2、高斯金字塔</h4> 
<p>  1.对图像做高斯平滑</p> 
<p>  2.对平滑后得图像做采样</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/d2/f4/2UMDCBbU_o.png"></p> 
<p>  </p> 
<h4 id="2.3%E3%80%81%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A">2.3、高斯模糊</h4> 
<p> 高斯模糊的目的是为了拟合人类视觉中对远近不同图像所产生的尺度差异与清晰度差异。</p> 
<p> 经过高斯模糊的图像会体现出总体模糊化，边缘清晰化的特征</p> 
<p>高斯模糊的具体做法是：</p> 
<blockquote> 
 <p>L(x,y,σ)=G(x,y,σ)∗I(x,y)<br> L(x,y,σ)=G(x,y,σ)∗I(x,y)<br> 其中，GG是高斯函数：<br> G(x,y,σ)=12πσ2ex2+y22σ2<br> G(x,y,σ)=12πσ2ex2+y22σ2<br> 其中，σσ是尺度空间因子，是高斯正态分布的标准差，反映了图像被模糊的程度，其值越大图像越模糊，对应的尺度也就越大，L(x,y,σ)L(x,y,σ)对应高斯尺度空间。<br> --------------------- <br> 作者：呆呆的猫 <br> 来源：CSDN <br> 原文：https://blog.csdn.net/jiaoyangwm/article/details/79986729 <br>  </p> 
</blockquote> 
<h4 id="%C2%A0%203.DOG%E7%A9%BA%E9%97%B4%E6%9E%81%E5%80%BC%E6%A3%80%E6%B5%8B">  3.DOG空间极值检测</h4> 
<p>      DOG层是由两个相邻的高斯空间图像层相减得到的，其目的是简化计算复杂度。</p> 
<h4 id="%C2%A04.%E5%88%A0%E9%99%A4%E8%BE%B9%E7%BC%98%E5%93%8D%E5%BA%94%E7%82%B9"> 4.删除边缘响应点</h4> 
<p>  一些噪声点会产生边缘响应，会影响匹配结果。可以通过尺度空间DoG函数进行曲线拟合寻找极值点，去除边缘响应点。</p> 
<p> </p> 
<h2 id="%E4%BA%8C%E3%80%81SIFT%E7%AE%97%E6%B3%95%E7%9A%84%E7%AE%80%E5%8D%95%E5%BA%94%E7%94%A8%E4%B8%8E%E5%92%8CHarris%E8%A7%92%E7%82%B9%E5%8C%B9%E9%85%8D%E7%9A%84%E5%AF%B9%E6%AF%94">二、SIFT算法的简单应用与和Harris角点匹配的对比</h2> 
<p>这次采用的实验原图片是集美大学的中山纪念馆。</p> 
<p><img alt="" class="has" height="354" src="https://images2.imgbox.com/dc/f4/GwKWYNp5_o.jpg" width="472"></p> 
<p><img alt="" class="has" height="352" src="https://images2.imgbox.com/b0/67/qSKo5wLh_o.jpg" width="470"></p> 
<p><img alt="" class="has" height="350" src="https://images2.imgbox.com/fc/f9/nRUy4nK6_o.jpg" width="467"></p> 
<p><img alt="" class="has" height="622" src="https://images2.imgbox.com/a4/45/1R0MucS5_o.jpg" width="466"></p> 
<p><img alt="" class="has" height="627" src="https://images2.imgbox.com/2b/c1/zREEU7ec_o.jpg" width="470"></p> 
<p><img alt="" class="has" height="353" src="https://images2.imgbox.com/10/80/ILlxu0If_o.jpg" width="471"></p> 
<p><img alt="" class="has" height="353" src="https://images2.imgbox.com/5f/51/bPkWmlHD_o.jpg" width="471"></p> 
<p><img alt="" class="has" height="355" src="https://images2.imgbox.com/85/2b/Z3UCPQAM_o.jpg" width="473"><img alt="" class="has" height="355" src="https://images2.imgbox.com/15/96/LEghaaHy_o.jpg" width="473"><img alt="" class="has" height="355" src="https://images2.imgbox.com/e9/74/jB2ZX8eV_o.jpg" width="473"></p> 
<p><img alt="" class="has" height="356" src="https://images2.imgbox.com/5e/7d/hbYzg4oA_o.jpg" width="475"><img alt="" class="has" height="359" src="https://images2.imgbox.com/41/e0/ts0QIbFb_o.jpg" width="479"></p> 
<p><img alt="" class="has" height="364" src="https://images2.imgbox.com/9e/f7/AyxouZSd_o.jpg" width="485"></p> 
<p><img alt="" class="has" height="367" src="https://images2.imgbox.com/be/ca/3ERjBOnT_o.jpg" width="490"></p> 
<p><img alt="" class="has" height="368" src="https://images2.imgbox.com/53/44/c5FPuZRx_o.jpg" width="491"></p> 
<p><img alt="" class="has" height="370" src="https://images2.imgbox.com/af/19/TLDjaR2I_o.jpg" width="494"></p> 
<p> </p> 
<p>首先我们任意选取两张图片分别进行Harris特征匹配处理与SIFT特征匹配处理的对比</p> 
<h3 id="1.Harris%E7%89%B9%E5%BE%81%E5%8C%B9%E9%85%8D%E5%A4%84%E7%90%86">1.Harris特征匹配处理</h3> 
<p>Harris 可以表示出图像的角点，具体实现代码如下</p> 
<pre class="has"><code>from scipy.ndimage import filters
from numpy import *
from PIL import Image
import harris
from pylab import *
import os

  
im=array(Image.open('1.jpg').convert('L'))
harrisim=harris.compute_harris_response(im)
filtered_coords=harris.get_harris_points(harrisim,6)
harris.plot_harris_points(im,filtered_coords)
</code></pre> 
<p>其中用到的harris函数实现方法如下：</p> 
<pre class="has"><code>from scipy.ndimage import filters
from numpy import *
from pylab import *

def compute_harris_response(im,sigma=3):
    # derivatives
    imx = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (0,1), imx)
    imy = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (1,0), imy)
    
    # compute components of the Harris matrix
    Wxx = filters.gaussian_filter(imx*imx,sigma)
    Wxy = filters.gaussian_filter(imx*imy,sigma)
    Wyy = filters.gaussian_filter(imy*imy,sigma)
    
    # determinant and trace
    Wdet = Wxx*Wyy - Wxy**2
    Wtr = Wxx + Wyy
    
    return Wdet / Wtr

def get_harris_points(harrisim,min_dist=10,threshold=0.1):
    """ Return corners from a Harris response image
        min_dist is the minimum number of pixels separating 
        corners and image boundary. """
    
    # find top corner candidates above a threshold
    corner_threshold = harrisim.max() * threshold
    harrisim_t = (harrisim &gt; corner_threshold) * 1
    
    # get coordinates of candidates
    coords = array(harrisim_t.nonzero()).T
    
    # ...and their values
    candidate_values = [harrisim[c[0],c[1]] for c in coords]
    
    # sort candidates (reverse to get descending order)
    index = argsort(candidate_values)[::-1]
    
    # store allowed point locations in array
    allowed_locations = zeros(harrisim.shape)
    allowed_locations[min_dist:-min_dist,min_dist:-min_dist] = 1
    
    # select the best points taking min_distance into account
    filtered_coords = []
    for i in index:
        if allowed_locations[coords[i,0],coords[i,1]] == 1:
            filtered_coords.append(coords[i])
            allowed_locations[(coords[i,0]-min_dist):(coords[i,0]+min_dist), 
                        (coords[i,1]-min_dist):(coords[i,1]+min_dist)] = 0
    
    return filtered_coords


def plot_harris_points(image,filtered_coords):
    """ Plots corners found in image. """
    
    figure()
    gray()
    imshow(image)
    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'*')
    axis('off')
    show()
def get_descriptors(image,filtered_coords,wid=5):
    """ For each point return pixel values around the point
        using a neighbourhood of width 2*wid+1. (Assume points are 
        extracted with min_distance &gt; wid). """
    
    desc = []
    for coords in filtered_coords:
        patch = image[coords[0]-wid:coords[0]+wid+1,
                            coords[1]-wid:coords[1]+wid+1].flatten()
        desc.append(patch)
    
    return desc
def match(desc1,desc2,threshold=0.5):
    """ For each corner point descriptor in the first image, 
        select its match to second image using
        normalized cross correlation. """
    
    n = len(desc1[0])
    
    # pair-wise distances
    d = -ones((len(desc1),len(desc2)))
    for i in range(len(desc1)):
        for j in range(len(desc2)):
            d1 = (desc1[i] - mean(desc1[i])) / std(desc1[i])
            d2 = (desc2[j] - mean(desc2[j])) / std(desc2[j])
            ncc_value = sum(d1 * d2) / (n-1) 
            if ncc_value &gt; threshold:
                d[i,j] = ncc_value
            
    ndx = argsort(-d)
    matchscores = ndx[:,0]
    
    return matchscores
def match_twosided(desc1,desc2,threshold=0.5):
    """ Two-sided symmetric version of match(). """
    
    matches_12 = match(desc1,desc2,threshold)
    matches_21 = match(desc2,desc1,threshold)
    
    ndx_12 = where(matches_12 &gt;= 0)[0]
    
    # remove matches that are not symmetric
    for n in ndx_12:
        if matches_21[matches_12[n]] != n:
            matches_12[n] = -1
    
    return matches_12
def appendimages(im1,im2):
    """ Return a new image that appends the two images side-by-side. """
    
    # select the image with the fewest rows and fill in enough empty rows
    rows1 = im1.shape[0]    
    rows2 = im2.shape[0]
    
    if rows1 &lt; rows2:
        im1 = concatenate((im1,zeros((rows2-rows1,im1.shape[1]))),axis=0)
    elif rows1 &gt; rows2:
        im2 = concatenate((im2,zeros((rows1-rows2,im2.shape[1]))),axis=0)
    # if none of these cases they are equal, no filling needed.
    
    return concatenate((im1,im2), axis=1)

def plot_matches(im1,im2,locs1,locs2,matchscores,show_below=True):
    """ Show a figure with lines joining the accepted matches 
        input: im1,im2 (images as arrays), locs1,locs2 (feature locations), 
        matchscores (as output from 'match()'), 
        show_below (if images should be shown below matches). """
    
    im3 = appendimages(im1,im2)
    if show_below:
        im3 = vstack((im3,im3))
    
    imshow(im3)
    
    cols1 = im1.shape[1]
    for i,m in enumerate(matchscores):
        if m&gt;0:
            plot([locs1[i][1],locs2[m][1]+cols1],[locs1[i][0],locs2[m][0]],'c')
    axis('off')

</code></pre> 
<p>实验原图与结果如下：</p> 
<p><img alt="" class="has" height="276" src="https://images2.imgbox.com/9e/0d/OUtVXzHq_o.jpg" width="368"><img alt="" class="has" height="280" src="https://images2.imgbox.com/be/4f/HPOAXCet_o.png" width="377"></p> 
<h3 id="2.Harris%E7%AE%97%E6%B3%95%E5%9C%A8%E5%9B%BE%E5%83%8F%E9%97%B4%E5%AF%BB%E6%89%BE%E5%AF%B9%E5%BA%94%E7%82%B9">2.Harris算法在图像间寻找对应点</h3> 
<p>    利用Harris算法比较一下两张图像之间的特征点</p> 
<p><img alt="" class="has" height="274" src="https://images2.imgbox.com/9e/18/msaPiDDu_o.jpg" width="365"><img alt="" class="has" height="271" src="https://images2.imgbox.com/4c/73/ZJpZhoel_o.jpg" width="361"></p> 
<p>代码实现部分：</p> 
<pre class="has"><code>from scipy.ndimage import filters
from numpy import *
from PIL import Image
import harris
from pylab import *
import os

def imresize(im,sz):
    """    Resize an image array using PIL. """
    pil_im = Image.fromarray(uint8(im))
    
    return array(pil_im.resize(sz))
  
im1 = array(Image.open('2.jpg').convert('L'))
im2 = array(Image.open('3.jpg').convert('L'))
im1 = imresize(im1, (int(im1.shape[1]/2), int(im1.shape[0]/2)))
im2 = imresize(im2, (int(im2.shape[1]/2), int(im2.shape[0]/2)))
wid=5
harrisim=harris.compute_harris_response(im1,5)
filtered_coords1=harris.get_harris_points(harrisim,wid+1)
d1=harris.get_descriptors(im1,filtered_coords1,wid)
harrisim=harris.compute_harris_response(im2,5)
filtered_coords2=harris.get_harris_points(harrisim,wid+1)
d2=harris.get_descriptors(im2,filtered_coords2,wid)
print ('starting matching')
matches=harris.match_twosided(d1,d2)

figure()
gray()
harris.plot_matches(im1,im2,filtered_coords1,filtered_coords2,matches)
show()</code></pre> 
<p>实验结果：<img alt="" class="has" height="527" src="https://images2.imgbox.com/42/cb/5VPvfhVJ_o.png" width="702"></p> 
<h3 id="3.SIFT%E7%AE%97%E6%B3%95%E6%A3%80%E6%B5%8B%E4%B8%8EHarris%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B%E5%AF%B9%E6%AF%94">3.SIFT算法检测与Harris角点检测对比</h3> 
<p>   <span style="color:#7c79e5;">这里要强调一个很重要、重要、重要的问题，就是VLfeat的配置以及PCV应用VLfeat工具包的问题。</span></p> 
<p><span style="color:#7c79e5;">   由于我第一次使用VLfeat工具包与PCV包，产生了非常麻烦的问题，差不多从困扰了我几个小时，在这里特别提出，希望读者在进行VLfeat工具包以及PCV包的配置时不会出现这个让人崩溃的问题。在PCV的sift函数里有一个函数，它导入了VLfeat包，在路径导入的时候，需要在前面加一个r，不然会出现各种各样莫名其妙的报错。</span></p> 
<p>下面这个是sift函数：</p> 
<pre class="has"><code>from PIL import Image
import os
from numpy import *
from pylab import *
from scipy.ndimage import filters
def imresize(im,sz):
    pil_im = Image.fromarray(uint8(im))
    
    return array(pil_im.resize(sz))

def compute_harris_response(im,sigma=3):
    imx = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (0,1), imx)
    imy = zeros(im.shape)
    filters.gaussian_filter(im, (sigma,sigma), (1,0), imy)
    
    Wxx = filters.gaussian_filter(imx*imx,sigma)
    Wxy = filters.gaussian_filter(imx*imy,sigma)
    Wyy = filters.gaussian_filter(imy*imy,sigma)
    
    Wdet = Wxx*Wyy - Wxy**2
    Wtr = Wxx + Wyy
    
    return Wdet / Wtr

def get_harris_points(harrisim,min_dist=10,threshold=0.1):
    corner_threshold = harrisim.max() * threshold
    harrisim_t = (harrisim &gt; corner_threshold) * 1
    
    coords = array(harrisim_t.nonzero()).T
    
    candidate_values = [harrisim[c[0],c[1]] for c in coords]
    
    index = argsort(candidate_values)[::-1]
    
    allowed_locations = zeros(harrisim.shape)
    allowed_locations[min_dist:-min_dist,min_dist:-min_dist] = 1
    
    filtered_coords = []
    for i in index:
        if allowed_locations[coords[i,0],coords[i,1]] == 1:
            filtered_coords.append(coords[i])
            allowed_locations[(coords[i,0]-min_dist):(coords[i,0]+min_dist), 
                        (coords[i,1]-min_dist):(coords[i,1]+min_dist)] = 0
    
    return filtered_coords


def plot_harris_points(image,filtered_coords):
    """ Plots corners found in image. """
    
    figure()
    gray()
    imshow(image)
    plot([p[1] for p in filtered_coords],[p[0] for p in filtered_coords],'*')
    axis('off')
    show()
def get_descriptors(image,filtered_coords,wid=5):
    """ For each point return pixel values around the point
        using a neighbourhood of width 2*wid+1. (Assume points are 
        extracted with min_distance &gt; wid). """
    
    desc = []
    for coords in filtered_coords:
        patch = image[coords[0]-wid:coords[0]+wid+1,
                            coords[1]-wid:coords[1]+wid+1].flatten()
        desc.append(patch)
    
    return desc
def match(desc1,desc2,threshold=0.5):
    """ For each corner point descriptor in the first image, 
        select its match to second image using
        normalized cross correlation. """
    
    n = len(desc1[0])
    
    # pair-wise distances
    d = -ones((len(desc1),len(desc2)))
    for i in range(len(desc1)):
        for j in range(len(desc2)):
            d1 = (desc1[i] - mean(desc1[i])) / std(desc1[i])
            d2 = (desc2[j] - mean(desc2[j])) / std(desc2[j])
            ncc_value = sum(d1 * d2) / (n-1) 
            if ncc_value &gt; threshold:
                d[i,j] = ncc_value
            
    ndx = argsort(-d)
    matchscores = ndx[:,0]
    
    return matchscores
def match_twosided(desc1,desc2,threshold=0.5):
    """ Two-sided symmetric version of match(). """
    
    matches_12 = match(desc1,desc2,threshold)
    matches_21 = match(desc2,desc1,threshold)
    
    ndx_12 = where(matches_12 &gt;= 0)[0]
    
    # remove matches that are not symmetric
    for n in ndx_12:
        if matches_21[matches_12[n]] != n:
            matches_12[n] = -1
    
    return matches_12
def appendimages(im1,im2):
    """ Return a new image that appends the two images side-by-side. """
    
    # select the image with the fewest rows and fill in enough empty rows
    rows1 = im1.shape[0]    
    rows2 = im2.shape[0]
    
    if rows1 &lt; rows2:
        im1 = concatenate((im1,zeros((rows2-rows1,im1.shape[1]))),axis=0)
    elif rows1 &gt; rows2:
        im2 = concatenate((im2,zeros((rows1-rows2,im2.shape[1]))),axis=0)
    # if none of these cases they are equal, no filling needed.
    
    return concatenate((im1,im2), axis=1)
def plot_matches(im1,im2,locs1,locs2,matchscores,show_below=True):
    """ Show a figure with lines joining the accepted matches 
        input: im1,im2 (images as arrays), locs1,locs2 (feature locations), 
        matchscores (as output from 'match()'), 
        show_below (if images should be shown below matches). """
    
    im3 = appendimages(im1,im2)
    if show_below:
        im3 = vstack((im3,im3))
    
    imshow(im3)
    
    cols1 = im1.shape[1]
    for i,m in enumerate(matchscores):
        if m&gt;0:
            plot([locs1[i][1],locs2[m][1]+cols1],[locs1[i][0],locs2[m][0]],'c')
    axis('off')
def process_image(imagename, resultname, params="--edge-thresh 10 --peak-thresh 5"):
    """ 处理一幅图像，然后将结果保存在文件中"""

    if imagename[-3:] != 'pgm':
        #创建一个pgm文件
        im = Image.open(imagename).convert('L')
        im.save('tmp.pgm')
        imagename ='tmp.pgm'
    cmmd = str(r"D:\VL20\vlfeat-0.9.20\bin\win64\sift.exe "+imagename+" --output="+resultname+" "+params)
    os.system(cmmd)

def read_features_from_file(filename):
    """读取特征属性值，然后将其以矩阵的形式返回"""
    f = loadtxt(filename)
    return f[:,:4], f[:,4:] #特征位置，描述子

def write_featrues_to_file(filename, locs, desc):
    """将特征位置和描述子保存到文件中"""
    savetxt(filename, hstack((locs,desc)))

def plot_features(im, locs, circle=False):
    """显示带有特征的图像
       输入：im（数组图像），locs（每个特征的行、列、尺度和朝向）"""

    def draw_circle(c,r):
        t = arange(0,1.01,.01)*2*pi
        x = r*cos(t) + c[0]
        y = r*sin(t) + c[1]
        plot(x, y, 'b', linewidth=2)

    imshow(im)
    if circle:
        for p in locs:
            draw_circle(p[:2], p[2])
    else: 
        plot(locs[:,0], locs[:,1], 'ob')
    axis('off')

</code></pre> 
<p>下面这个就是那个令人崩溃的函数：</p> 
<pre class="has"><code>
def process_image(imagename, resultname, params="--edge-thresh 10 --peak-thresh 5"):
    """ 处理一幅图像，然后将结果保存在文件中"""

    if imagename[-3:] != 'pgm':
        #创建一个pgm文件
        im = Image.open(imagename).convert('L')
        im.save('tmp.pgm')
        imagename ='tmp.pgm'
    cmmd = str(r"D:\VL20\vlfeat-0.9.20\bin\win64\sift.exe "+imagename+" --output="+resultname+" "+params)
    os.system(cmmd)</code></pre> 
<p>下面是实现SIFT匹配和Harris角点匹配算法的对比：</p> 
<pre class="has"><code>from PIL import Image
from pylab import *
from PCV.localdescriptors import sift
from PCV.localdescriptors import harris

# 添加中文字体支持
from matplotlib.font_manager import FontProperties
font = FontProperties(fname=r"c:\windows\fonts\SimSun.ttc", size=14)

imname = '2.jpg'
im = array(Image.open(imname).convert('L'))
sift.process_image(imname, 'empire.sift')
l1, d1 = sift.read_features_from_file('empire.sift')

figure()
gray()
subplot(131)
sift.plot_features(im, l1, circle=False)
title(u'SIFT特征',fontproperties=font)
subplot(132)
sift.plot_features(im, l1, circle=True)
title(u'用圆圈表示SIFT特征尺度',fontproperties=font)

# 检测harris角点
harrisim = harris.compute_harris_response(im)

subplot(133)
filtered_coords = harris.get_harris_points(harrisim, 6, 0.1)
imshow(im)
plot([p[1] for p in filtered_coords], [p[0] for p in filtered_coords], '*')
axis('off')
title(u'Harris角点',fontproperties=font)

show()
</code></pre> 
<p>以下是实验结果：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/16/c1/yEkJacak_o.png"></p> 
<p>可以明显看到SIFT所确定的特征逼Harris角点要优秀，并且在图片大小较大的时候，SIFT的鲁棒性要优于Harris角点：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/ba/ce/h6lqPNmj_o.png"></p> 
<p>可以看到在这个时候，SIFT依然很正常得计算出了结果，然而Harris角点已然失效。</p> 
<h3 id="4.SIFT%E7%AE%97%E6%B3%95%E5%8C%B9%E9%85%8D">4.SIFT算法匹配</h3> 
<p>以下是实现算法</p> 
<pre class="has"><code>from PIL import Image
from pylab import *
import sys
from PCV.localdescriptors import sift


if len(sys.argv) &gt;= 3:
  im1f, im2f = sys.argv[1], sys.argv[2]
else:
#  im1f = '../data/sf_view1.jpg'
#  im2f = '../data/sf_view2.jpg'
  im1f = '1.jpg'
  im2f = '2.jpg'
#  im1f = '../data/climbing_1_small.jpg'
#  im2f = '../data/climbing_2_small.jpg'
im1 = array(Image.open(im1f))
im2 = array(Image.open(im2f))

sift.process_image(im1f, 'out_sift_1.txt')
l1, d1 = sift.read_features_from_file('out_sift_1.txt')
figure()
gray()
subplot(121)
sift.plot_features(im1, l1, circle=False)

sift.process_image(im2f, 'out_sift_2.txt')
l2, d2 = sift.read_features_from_file('out_sift_2.txt')
subplot(122)
sift.plot_features(im2, l2, circle=False)

#matches = sift.match(d1, d2)
matches = sift.match_twosided(d1, d2)
print ('{} matches').format(len(matches.nonzero()[0]))

figure()
gray()
sift.plot_matches(im1, im2, l1, l2, matches, show_below=True)
show()

</code></pre> 
<p>   以下是上诉代码的匹配结果：</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/f2/69/l8No1iV5_o.png"></p> 
<h3>5.pylot的应用</h3> 
<pre class="has"><code>(graph_type='graph')

g.add_node(pydot.Node(str(0), fontcolor='transparent'))
for i in range(5):
  g.add_node(pydot.Node(str(i + 1)))
  g.add_edge(pydot.Edge(str(0), str(i + 1)))
  for j in range(5):
    g.add_node(pydot.Node(str(j + 1) + '0' + str(i + 1)))
    g.add_edge(pydot.Edge(str(j + 1) + '0' + str(i + 1), str(j + 1)))
  g.write_png('C:/Users/ASUS/Desktop/Ss/computerview/FIRST Demo/image/ a.png ', prog='neato')

</code></pre> 
<p>要注意这里保存文件的斜杠要用好，方向错了会十分麻烦。</p> 
<p><img alt="" class="has" src="https://images2.imgbox.com/92/37/rjLinX7f_o.png"></p> 
<p> </p> 
<p> </p> 
<h2 id="%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD%E3%80%82%E3%80%82%E3%80%82%EF%BC%88%E4%BB%A3%E7%A0%81%E8%B7%91%E5%BE%97%E6%9C%89%E7%82%B9%E6%85%A2%EF%BC%89">未完待续。。。（代码跑得有点慢）</h2> 
<h2> </h2> 
<p> </p> 
<p> </p> 
<p> </p>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/6c10a3c0eeebee23fe88bcc8e06dead6/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux系统下安装nginx详细步骤！（亲测）</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/36aeeb62b5fe3bfd112d0aa379f059af/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">怎样写好git comment</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>