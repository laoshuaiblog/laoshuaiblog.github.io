<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>手撕/手写/自己实现 BN层/batch norm/BatchNormalization python torch pytorch - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/46de638c975b70bebfe5918bc49f9e9c/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="手撕/手写/自己实现 BN层/batch norm/BatchNormalization python torch pytorch">
  <meta property="og:description" content="计算过程 在卷积神经网络中，BN 层输入的特征图维度是 （N,C,H,W）, 输出的特征图维度也是 （N,C,H,W）
N 代表 batch size
C 代表 通道数
H 代表 特征图的高
W 代表 特征图的宽
我们需要在通道维度上做 batch normalization，
在一个 batch 中，
使用 所有特征图 相同位置上的 channel 的 所有元素，计算 均值和方差，
然后用计算出来的 均值和 方差，更新对应特征图上的 channel ， 生成新的特征图
如下图所示：
对于4个橘色的特征图，计算所有元素的均值和方差，然后在用于更新4个特征图中的元素（原来元素减去均值，除以方差）
代码 def my_batch_norm_2d_detail(features, eps=1e-5): &#39;&#39;&#39; 这个函数的写法是为了帮助理解 BatchNormalization 具体运算过程 实际使用时这样写会比较慢 &#39;&#39;&#39; n,c,h,w = features.shape features_copy = features.clone() running_var = torch.randn(c) running_mean = torch.randn(c) for ci in range(c):# 分别 处理每一个通道 mean = 0 # 均值 var = 0 # 方差 _sum = 0 # 对一个 batch 中，特征图相同位置 channel 的每一个元素求和 for ni in range(n): for hi in range(h): for wi in range(w): _sum &#43;= features[ni,ci, hi, wi] mean = _sum / (n * h * w) running_mean[ci] = mean _sum = 0 # 对一个 batch 中，特征图相同位置 channel 的每一个元素求平方和，用于计算方差 for ni in range(n): for hi in range(h): for wi in range(w): _sum &#43;= (features[ni,ci, hi, wi] - mean) ** 2 var = _sum / (n * h * w ) running_var[ci] = _sum / (n * h * w - 1) # 更新元素 for ni in range(n): for hi in range(h): for wi in range(w): features_copy[ni,ci, hi, wi] = (features_copy[ni,ci, hi, wi] - mean) / torch.">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-04-08T15:33:03+08:00">
    <meta property="article:modified_time" content="2023-04-08T15:33:03+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">手撕/手写/自己实现 BN层/batch norm/BatchNormalization python torch pytorch</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-atom-one-dark">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>计算过程</h2> 
<p>在卷积神经网络中，BN 层输入的特征图维度是 （N,C,H,W）, 输出的特征图维度也是 （N,C,H,W）<br> N 代表 batch size<br> C 代表 通道数<br> H 代表 特征图的高<br> W 代表 特征图的宽</p> 
<p>我们需要在通道维度上做 batch normalization，<br> 在一个 batch 中，<br> 使用 所有特征图 相同位置上的 channel 的 所有元素，计算 均值和方差，<br> 然后用计算出来的 均值和 方差，更新对应特征图上的 channel ， 生成新的特征图</p> 
<p>如下图所示：<br> 对于4个橘色的特征图，计算所有元素的均值和方差，然后在用于更新4个特征图中的元素（原来元素减去均值，除以方差）<br> <img src="https://images2.imgbox.com/d8/54/95zwAibZ_o.png" alt="![[attachments/BN示意图.png]]"></p> 
<h2><a id="_19"></a>代码</h2> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">my_batch_norm_2d_detail</span><span class="token punctuation">(</span>features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
        这个函数的写法是为了帮助理解 BatchNormalization 具体运算过程
        实际使用时这样写会比较慢
    '''</span>
    
    n<span class="token punctuation">,</span>c<span class="token punctuation">,</span>h<span class="token punctuation">,</span>w <span class="token operator">=</span> features<span class="token punctuation">.</span>shape
    features_copy <span class="token operator">=</span> features<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>
    running_var <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    running_mean <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>c<span class="token punctuation">)</span>
    <span class="token keyword">for</span> ci <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>c<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token comment"># 分别 处理每一个通道</span>
        mean <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment"># 均值</span>
        var <span class="token operator">=</span> <span class="token number">0</span> <span class="token comment"># 方差</span>
        
        _sum <span class="token operator">=</span> <span class="token number">0</span> 
        <span class="token comment"># 对一个 batch 中，特征图相同位置 channel 的每一个元素求和</span>
        <span class="token keyword">for</span> ni <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            
            <span class="token keyword">for</span> hi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> wi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    _sum <span class="token operator">+=</span> features<span class="token punctuation">[</span>ni<span class="token punctuation">,</span>ci<span class="token punctuation">,</span> hi<span class="token punctuation">,</span> wi<span class="token punctuation">]</span>
        mean <span class="token operator">=</span> _sum <span class="token operator">/</span> <span class="token punctuation">(</span>n <span class="token operator">*</span> h <span class="token operator">*</span> w<span class="token punctuation">)</span> 
        running_mean<span class="token punctuation">[</span>ci<span class="token punctuation">]</span> <span class="token operator">=</span> mean
        

        _sum <span class="token operator">=</span> <span class="token number">0</span>
        <span class="token comment"># 对一个 batch 中，特征图相同位置 channel 的每一个元素求平方和，用于计算方差 </span>
        <span class="token keyword">for</span> ni <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            
            <span class="token keyword">for</span> hi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> wi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    _sum <span class="token operator">+=</span> <span class="token punctuation">(</span>features<span class="token punctuation">[</span>ni<span class="token punctuation">,</span>ci<span class="token punctuation">,</span> hi<span class="token punctuation">,</span> wi<span class="token punctuation">]</span> <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">**</span> <span class="token number">2</span>
        var <span class="token operator">=</span> _sum <span class="token operator">/</span> <span class="token punctuation">(</span>n <span class="token operator">*</span> h <span class="token operator">*</span> w <span class="token punctuation">)</span>
        running_var<span class="token punctuation">[</span>ci<span class="token punctuation">]</span> <span class="token operator">=</span> _sum <span class="token operator">/</span> <span class="token punctuation">(</span>n <span class="token operator">*</span> h <span class="token operator">*</span> w <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>

        <span class="token comment"># 更新元素</span>
        <span class="token keyword">for</span> ni <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">:</span>            
            <span class="token keyword">for</span> hi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>h<span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">for</span> wi <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>w<span class="token punctuation">)</span><span class="token punctuation">:</span>
                    features_copy<span class="token punctuation">[</span>ni<span class="token punctuation">,</span>ci<span class="token punctuation">,</span> hi<span class="token punctuation">,</span> wi<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>features_copy<span class="token punctuation">[</span>ni<span class="token punctuation">,</span>ci<span class="token punctuation">,</span> hi<span class="token punctuation">,</span> wi<span class="token punctuation">]</span> <span class="token operator">-</span> mean<span class="token punctuation">)</span> <span class="token operator">/</span> torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var <span class="token operator">+</span> eps<span class="token punctuation">)</span> 
        
    <span class="token keyword">return</span> features_copy<span class="token punctuation">,</span> running_mean<span class="token punctuation">,</span> running_var

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">"__main__"</span><span class="token punctuation">:</span>


    torch<span class="token punctuation">.</span>set_printoptions<span class="token punctuation">(</span>precision<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>

    torch_bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>  <span class="token comment"># 设置 channel 数</span>
    torch_bn<span class="token punctuation">.</span>momentum <span class="token operator">=</span> <span class="token boolean">None</span>
    features <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token comment"># (N,C,H,W)</span>
        
    torch_bn_output <span class="token operator">=</span> torch_bn<span class="token punctuation">(</span>features<span class="token punctuation">)</span>    
    my_bn_output<span class="token punctuation">,</span> running_mean<span class="token punctuation">,</span> running_var <span class="token operator">=</span> my_batch_norm_2d_detail<span class="token punctuation">(</span>features<span class="token punctuation">)</span>        
            
    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>torch_bn_output<span class="token punctuation">,</span> my_bn_output<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>torch_bn<span class="token punctuation">.</span>running_mean<span class="token punctuation">,</span> running_mean<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>torch_bn<span class="token punctuation">.</span>running_var<span class="token punctuation">,</span> running_var<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre> 
<h2><a id="_79"></a>注意事项</h2> 
<h3><a id="_81"></a>方差计算</h3> 
<p>需要注意的是，在训练的过程中，方差有两种不同的计算方式，</p> 
<p>在训练时，用于更新特征图的是 有偏方差<br> 而 running_var 的计算，使用的是 无偏方差<br> <img src="https://images2.imgbox.com/b3/9d/FFhsnH1Y_o.png" alt="在这里插入图片描述"></p> 
<h2><a id="_90"></a>相关链接</h2> 
<p><a href="https://github.com/ptrblck/pytorch_misc/blob/master/batch_norm_manual.py#L62">官方人员手写BN</a></p> 
<pre><code class="prism language-python"><span class="token triple-quoted-string string">"""
Comparison of manual BatchNorm2d layer implementation in Python and
nn.BatchNorm2d

@author: ptrblck
"""</span>

<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn


<span class="token keyword">def</span> <span class="token function">compare_bn</span><span class="token punctuation">(</span>bn1<span class="token punctuation">,</span> bn2<span class="token punctuation">)</span><span class="token punctuation">:</span>
    err <span class="token operator">=</span> <span class="token boolean">False</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>bn1<span class="token punctuation">.</span>running_mean<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Diff in running_mean: {} vs {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            bn1<span class="token punctuation">.</span>running_mean<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>running_mean<span class="token punctuation">)</span><span class="token punctuation">)</span>
        err <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>bn1<span class="token punctuation">.</span>running_var<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>running_var<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Diff in running_var: {} vs {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
            bn1<span class="token punctuation">.</span>running_var<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>running_var<span class="token punctuation">)</span><span class="token punctuation">)</span>
        err <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">if</span> bn1<span class="token punctuation">.</span>affine <span class="token keyword">and</span> bn2<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>bn1<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Diff in weight: {} vs {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                bn1<span class="token punctuation">.</span>weight<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>weight<span class="token punctuation">)</span><span class="token punctuation">)</span>
            err <span class="token operator">=</span> <span class="token boolean">True</span>

        <span class="token keyword">if</span> <span class="token keyword">not</span> torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>bn1<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Diff in bias: {} vs {}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                bn1<span class="token punctuation">.</span>bias<span class="token punctuation">,</span> bn2<span class="token punctuation">.</span>bias<span class="token punctuation">)</span><span class="token punctuation">)</span>
            err <span class="token operator">=</span> <span class="token boolean">True</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> err<span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'All parameters are equal!'</span><span class="token punctuation">)</span>


<span class="token keyword">class</span> <span class="token class-name">MyBatchNorm2d</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_features<span class="token punctuation">,</span> eps<span class="token operator">=</span><span class="token number">1e-5</span><span class="token punctuation">,</span> momentum<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span>
                 affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> track_running_stats<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>MyBatchNorm2d<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span>
            num_features<span class="token punctuation">,</span> eps<span class="token punctuation">,</span> momentum<span class="token punctuation">,</span> affine<span class="token punctuation">,</span> track_running_stats<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        self<span class="token punctuation">.</span>_check_input_dim<span class="token punctuation">(</span><span class="token builtin">input</span><span class="token punctuation">)</span>

        exponential_average_factor <span class="token operator">=</span> <span class="token number">0.0</span>

        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training <span class="token keyword">and</span> self<span class="token punctuation">.</span>track_running_stats<span class="token punctuation">:</span>
            <span class="token keyword">if</span> self<span class="token punctuation">.</span>num_batches_tracked <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>num_batches_tracked <span class="token operator">+=</span> <span class="token number">1</span>
                <span class="token keyword">if</span> self<span class="token punctuation">.</span>momentum <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>  <span class="token comment"># use cumulative moving average</span>
                    exponential_average_factor <span class="token operator">=</span> <span class="token number">1.0</span> <span class="token operator">/</span> <span class="token builtin">float</span><span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_batches_tracked<span class="token punctuation">)</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>  <span class="token comment"># use exponential moving average</span>
                    exponential_average_factor <span class="token operator">=</span> self<span class="token punctuation">.</span>momentum

        <span class="token comment"># calculate running estimates</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>training<span class="token punctuation">:</span>
            mean <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
            <span class="token comment"># use biased var in train</span>
            var <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>var<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> unbiased<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
            n <span class="token operator">=</span> <span class="token builtin">input</span><span class="token punctuation">.</span>numel<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token builtin">input</span><span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
            <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                self<span class="token punctuation">.</span>running_mean <span class="token operator">=</span> exponential_average_factor <span class="token operator">*</span> mean\
                    <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> exponential_average_factor<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>running_mean
                <span class="token comment"># update running_var with unbiased var</span>
                self<span class="token punctuation">.</span>running_var <span class="token operator">=</span> exponential_average_factor <span class="token operator">*</span> var <span class="token operator">*</span> n <span class="token operator">/</span> <span class="token punctuation">(</span>n <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span>\
                    <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> exponential_average_factor<span class="token punctuation">)</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>running_var
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            mean <span class="token operator">=</span> self<span class="token punctuation">.</span>running_mean
            var <span class="token operator">=</span> self<span class="token punctuation">.</span>running_var

        <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token builtin">input</span> <span class="token operator">-</span> mean<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>torch<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>var<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>eps<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> self<span class="token punctuation">.</span>affine<span class="token punctuation">:</span>
            <span class="token builtin">input</span> <span class="token operator">=</span> <span class="token builtin">input</span> <span class="token operator">*</span> self<span class="token punctuation">.</span>weight<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>bias<span class="token punctuation">[</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">]</span>

        <span class="token keyword">return</span> <span class="token builtin">input</span>


<span class="token comment"># Init BatchNorm layers</span>
my_bn <span class="token operator">=</span> MyBatchNorm2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
bn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BatchNorm2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> affine<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

compare_bn<span class="token punctuation">(</span>my_bn<span class="token punctuation">,</span> bn<span class="token punctuation">)</span>  <span class="token comment"># weight and bias should be different</span>
<span class="token comment"># Load weight and bias</span>
my_bn<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>bn<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
compare_bn<span class="token punctuation">(</span>my_bn<span class="token punctuation">,</span> bn<span class="token punctuation">)</span>

<span class="token comment"># Run train</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">*</span> scale <span class="token operator">+</span> bias
    out1 <span class="token operator">=</span> my_bn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    out2 <span class="token operator">=</span> bn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    compare_bn<span class="token punctuation">(</span>my_bn<span class="token punctuation">,</span> bn<span class="token punctuation">)</span>

    torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>out1<span class="token punctuation">,</span> out2<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Max diff: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>out1 <span class="token operator">-</span> out2<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment"># Run eval</span>
my_bn<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
bn<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    scale <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    bias <span class="token operator">=</span> torch<span class="token punctuation">.</span>randint<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">float</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    x <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">,</span> <span class="token number">100</span><span class="token punctuation">)</span> <span class="token operator">*</span> scale <span class="token operator">+</span> bias
    out1 <span class="token operator">=</span> my_bn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    out2 <span class="token operator">=</span> bn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    compare_bn<span class="token punctuation">(</span>my_bn<span class="token punctuation">,</span> bn<span class="token punctuation">)</span>

    torch<span class="token punctuation">.</span>allclose<span class="token punctuation">(</span>out1<span class="token punctuation">,</span> out2<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Max diff: '</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>out1 <span class="token operator">-</span> out2<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">max</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/97413cc2edb0cb603ff36843aaf0bc89/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">Linux安装nginx详细步骤</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e7fc3eed72b2328ef543c96df090d975/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">如何设计秒杀系统（三）</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>