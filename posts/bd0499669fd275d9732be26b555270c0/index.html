<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>sklearn聚类模型评估代码_sklearn中模型评估和预测 - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/bd0499669fd275d9732be26b555270c0/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="sklearn聚类模型评估代码_sklearn中模型评估和预测">
  <meta property="og:description" content="一、模型验证方法如下：
通过交叉验证得分：model_sleection.cross_val_score(estimator,X)
对每个输入数据点产生交叉验证估计：model_selection.cross_val_predict(estimator,X)
计算并绘制模型的学习率曲线：model_selection.learning_curve(estimator,X,y)
计算并绘制模型的验证曲线：model_selection.validation(estimator,...)
通过排序评估交叉验证的得分在重要性：model_selection.permutation_test_score(...)
①通过交叉验证得分：model_sleection.cross_val_score(estimator,X)
import numpy as np
from sklearn.model_selection import cross_val_score
from sklearn import datasets,svm
digits=datasets.load_digits()
X=digits.data
y=digits.target
svc=svm.SVC(kernel=&#39;linear&#39;)
C_s=np.logspace(-10,0,10)
print(&#34;参数列表长度&#34;,len(C_s))
scores=list()
scores_std=list()
n_folds=3
for C in C_s:
svc.C=C
this_scores=cross_val_score(svc,X,y,cv=n_folds,n_jobs=1)
#print(this_scores)
scores.append(np.mean(this_scores))
scores_std.append(np.std(this_scores))
#绘制交叉验证的曲线
import matplotlib.pyplot as plt
plt.figure(1,figsize=(4,3))
plt.clf()
plt.semilogx(C_s,scores)
plt.semilogx(C_s,np.array(scores)&#43;np.array(scores_std),&#39;b--&#39;)
plt.semilogx(C_s,np.array(scores)-np.array(scores_std),&#39;b--&#39;)
locs,labels=plt.yticks()
plt.yticks(locs,list(map(lambda x:&#34;%g&#34; %x,locs)))
plt.ylabel(&#34;CV score&#34;)
plt.xlabel(&#34;Parameter C&#34;)
plt.ylim(0,1.1)
plt.show()
结果图
②对每个输入数据点产生交叉验证估计：model_selection.cross_val_predict(estimator,X)
from sklearn import datasets,linear_model
from sklearn.model_selection import cross_val_predict
disbetes=datasets.load_diabetes()
X=disbetes.data[:150]">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2020-12-24T11:02:54+08:00">
    <meta property="article:modified_time" content="2020-12-24T11:02:54+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">sklearn聚类模型评估代码_sklearn中模型评估和预测</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="htmledit_views">
                    <div style="font-size:16px;"> 
 <p>一、模型验证方法如下：</p> 
 <p>通过交叉验证得分：model_sleection.cross_val_score(estimator,X)</p> 
 <p>对每个输入数据点产生交叉验证估计：model_selection.cross_val_predict(estimator,X)</p> 
 <p>计算并绘制模型的学习率曲线：model_selection.learning_curve(estimator,X,y)</p> 
 <p>计算并绘制模型的验证曲线：model_selection.validation(estimator,...)</p> 
 <p>通过排序评估交叉验证的得分在重要性：model_selection.permutation_test_score(...)</p> 
 <p>①通过交叉验证得分：model_sleection.cross_val_score(estimator,X)</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>import numpy as np</p> 
 <p>from sklearn.model_selection import cross_val_score</p> 
 <p>from sklearn import datasets,svm</p> 
 <p>digits=datasets.load_digits()</p> 
 <p>X=digits.data</p> 
 <p>y=digits.target</p> 
 <p>svc=svm.SVC(kernel='linear')</p> 
 <p>C_s=np.logspace(-10,0,10)</p> 
 <p>print("参数列表长度",len(C_s))</p> 
 <p>scores=list()</p> 
 <p>scores_std=list()</p> 
 <p>n_folds=3</p> 
 <p>for C in C_s:</p> 
 <p>svc.C=C</p> 
 <p>this_scores=cross_val_score(svc,X,y,cv=n_folds,n_jobs=1)</p> 
 <p>#print(this_scores)</p> 
 <p>scores.append(np.mean(this_scores))</p> 
 <p>scores_std.append(np.std(this_scores))</p> 
 <p>#绘制交叉验证的曲线</p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p>plt.figure(1,figsize=(4,3))</p> 
 <p>plt.clf()</p> 
 <p>plt.semilogx(C_s,scores)</p> 
 <p>plt.semilogx(C_s,np.array(scores)+np.array(scores_std),'b--')</p> 
 <p>plt.semilogx(C_s,np.array(scores)-np.array(scores_std),'b--')</p> 
 <p>locs,labels=plt.yticks()</p> 
 <p>plt.yticks(locs,list(map(lambda x:"%g" %x,locs)))</p> 
 <p>plt.ylabel("CV score")</p> 
 <p>plt.xlabel("Parameter C")</p> 
 <p>plt.ylim(0,1.1)</p> 
 <p>plt.show()</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>结果图</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>②对每个输入数据点产生交叉验证估计：model_selection.cross_val_predict(estimator,X)</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>from sklearn import datasets,linear_model</p> 
 <p>from sklearn.model_selection import cross_val_predict</p> 
 <p>disbetes=datasets.load_diabetes()</p> 
 <p>X=disbetes.data[:150]</p> 
 <p>y=disbetes.target[:150]</p> 
 <p>lasso=linear_model.Lasso()</p> 
 <p>y_pred=cross_val_predict(lasso,X,y)</p> 
 <p>print(y_pred)</p> 
 <p>结果：</p> 
 <p>[ 174.26933996 117.6539241 164.60228641 155.65049088 132.68647979</p> 
 <p>128.49511245 120.76146877 141.069413 164.18904498 182.37394949</p> 
 <p>111.04181265 127.94311443 135.0869234 162.83066014 135.3573514</p> 
 <p>157.64516523 178.95843326 163.3919841 143.85237903 144.29748882</p> 
 <p>133.58117218 124.77928571 132.90918003 208.52927 153.61908967</p> 
 <p>154.16616341 118.95351821 163.50467541 145.89406196 168.3308101</p> 
 <p>155.87411031 123.45960148 185.70459144 133.38468582 117.2789469</p> 
 <p>150.27895019 174.1541028 160.03235091 192.31389633 161.58568256</p> 
 <p>154.2224809 119.35517679 146.15706413 133.82056934 179.68118754</p> 
 <p>137.96619936 146.07788398 126.77579723 123.32101099 166.26710247</p> 
 <p>146.41559964 161.67261029 147.47731459 138.44595305 144.85421048</p> 
 <p>113.77990664 185.54970402 115.31624749 142.23672103 171.07792136</p> 
 <p>132.5394716 177.80524864 116.5616502 134.25230846 142.88707475</p> 
 <p>173.2830912 154.31273504 149.16680759 144.88238997 121.97783103</p> 
 <p>110.38457621 180.25559631 199.06141058 151.1195546 161.14217698</p> 
 <p>153.96960812 150.77179755 113.30903579 165.15755771 115.85735727</p> 
 <p>174.19267171 150.12027233 115.47891783 153.38967232 115.31573467</p> 
 <p>156.49909623 92.62211515 178.15649994 131.59320715 134.46166754</p> 
 <p>116.97678633 190.00790119 166.01173292 126.25944471 134.29256991</p> 
 <p>144.71971963 190.9769591 182.39199466 154.45325308 148.30325558</p> 
 <p>151.72036937 124.12825466 138.6011155 137.75891286 123.0917243</p> 
 <p>131.74735403 112.07367481 124.56956904 156.78432061 128.63135591</p> 
 <p>93.68260079 130.54324394 131.8693231 154.5708257 179.81343019</p> 
 <p>165.78130755 150.04779033 162.37974736 143.92996797 143.15645843</p> 
 <p>125.20161377 145.99590279 155.3505536 145.97574185 134.66120515</p> 
 <p>163.92450638 101.92329396 139.33014324 122.71377023 152.20573113</p> 
 <p>153.36931089 116.76545147 131.96936127 109.74817383 132.57453994</p> 
 <p>159.38030328 109.31343881 147.69926269 156.3664255 161.12509958</p> 
 <p>128.16523686 156.78446286 154.04375702 124.83705022 143.85606595</p> 
 <p>143.23651701 147.76316913 154.21572891 129.07895017 157.79644923]</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>③、计算并绘制模型的学习率曲线：model_selection.learning_curve(estimator,X,y)</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>import numpy as np</p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p>from sklearn.naive_bayes import GaussianNB</p> 
 <p>from sklearn.svm import SVC</p> 
 <p>from sklearn.datasets import load_digits</p> 
 <p>from sklearn.model_selection import learning_curve</p> 
 <p>from sklearn.model_selection import ShuffleSplit</p> 
 <p>def plt_learning_curve(estimator,title,X,y,ylim=None,cv=None,n_jobs=1,train_size=np.linspace(.1,1.0,5)):</p> 
 <p>plt.figure()</p> 
 <p>plt.title(title)</p> 
 <p>if ylim is not None:</p> 
 <p>plt.ylim(*ylim)</p> 
 <p>plt.xlabel("Training examples")</p> 
 <p>plt.ylabel("Score")</p> 
 <p>train_sizes,train_scores,test_scores=learning_curve(</p> 
 <p>estimator,X,y,cv=cv,n_jobs=n_jobs,train_sizes=train_size)</p> 
 <p>train_scores_mean=np.mean(train_scores,axis=1)</p> 
 <p>train_scores_std=np.std(train_scores,axis=1)</p> 
 <p>test_scores_mean=np.mean(test_scores,axis=1)</p> 
 <p>test_scores_std=np.std(test_scores,axis=1)</p> 
 <p>plt.grid()</p> 
 <p>plt.fill_between(train_sizes,train_scores_mean-train_scores_std,train_scores_mean+train_scores_std,alpha=0.1,color="r")</p> 
 <p>plt.fill_between(train_sizes,test_scores_mean-test_scores_std,test_scores_mean+test_scores_std,alpha=0.1,color="g")</p> 
 <p>plt.plot(train_sizes,train_scores_mean,"o-",color="r",label="Training score")</p> 
 <p>plt.plot(train_sizes,test_scores_mean,"o-",color="g",label="Cross-validation score")</p> 
 <p>plt.legend(loc="best")</p> 
 <p>return plt</p> 
 <p>digits=load_digits()</p> 
 <p>X,y=digits.data,digits.target</p> 
 <p>title="Learning Curves(Nativr Bayes)"</p> 
 <p>cv=ShuffleSplit(n_splits=100,test_size=0.2,random_state=0)</p> 
 <p>estimator=GaussianNB()</p> 
 <p>plt_learning_curve(estimator,title,X,y,ylim=(0.7,1.0),cv=cv,n_jobs=1)</p> 
 <p>title="Learnming Curves (SVM,RBF kernel,$\gamma=0.001$)"</p> 
 <p>cv=ShuffleSplit(n_splits=10,test_size=0.2,random_state=0)</p> 
 <p>estimator=SVC(gamma=0.001)</p> 
 <p>plt_learning_curve(estimator,title,X,y,(0.7,1.01),cv=cv,n_jobs=1)</p> 
 <p>plt.show()</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>④、计算并绘制模型的验证曲线：model_selection.validation(estimator,...)</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>import matplotlib.pyplot as plt</p> 
 <p>import numpy as np</p> 
 <p>from sklearn.datasets import load_digits</p> 
 <p>from sklearn.svm import SVC</p> 
 <p>from sklearn.model_selection import validation_curve</p> 
 <p>digits = load_digits()</p> 
 <p>param_range=np.logspace(-6,-1,5)</p> 
 <p>train_scores,test_scores=validation_curve(SVC(),X,y,param_name="gamma",param_range=param_range,</p> 
 <p>cv=10,scoring="accuracy",n_jobs=1)</p> 
 <p>train_scores_mean=np.mean(train_scores,axis=1)</p> 
 <p>train_scores_std=np.std(train_scores,axis=1)</p> 
 <p>test_scores_mean=np.mean(test_scores,axis=1)</p> 
 <p>test_scores_std=np.std(test_scores,axis=1)</p> 
 <p>plt.title("Validation Curve with SVM")</p> 
 <p>plt.xlabel("$\gamma$")</p> 
 <p>plt.ylabel("Score")</p> 
 <p>plt.ylim(0.0,1.1)</p> 
 <p>lw=2</p> 
 <p>plt.semilogx(param_range,train_scores_mean,label="Training score",color="darkorange",lw=lw)</p> 
 <p>plt.fill_between(param_range,train_scores_mean-train_scores_std,train_scores_mean+train_scores_std,</p> 
 <p>alpha=0.2,color="darkorange",lw=lw)</p> 
 <p>plt.semilogx(param_range,test_scores_mean,label="Cross-validation Score",color="navy",lw=lw)</p> 
 <p>plt.fill_between(param_range,test_scores_mean-test_scores_std,test_scores_mean+test_scores_std,</p> 
 <p>alpha=0.2,color="navy",lw=lw)</p> 
 <p>plt.legend(loc="best")</p> 
 <p>plt.show()</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>⑤、通过排序评估交叉验证的得分在重要性：model_selection.permutation_test_score(...)---现在用的很少</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>二、模型评估方法</p> 
 <p>sklearn模型预测性能的评估方法</p> 
 <p>Estimator对象的score方法</p> 
 <p>在交叉验证中使用的scoring参数</p> 
 <p>Estimator对象的score方法</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>score(self,X,y,y_true)函数在内部会调用predict函数获得预测响应y_predict,然后与传人的真实响应进行比较，计算得分</p> 
 <p>使用estimator的score函数来苹果模型的性能，默认情况下</p> 
 <p>分类器对应于准确率：sklearn.metrics.accuracy_score</p> 
 <p>回归器对应于R2得分：sklearn.metrics.r2_score</p> 
 <p>在交叉验证中使用scoring参数</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>上面的两个模型选择工具中都有一个参数“scoring”，该参数用来指定在进行网格搜索或计算交叉验证得分的时候，用什么标砖度量“estimator”的预测性能。默认情况下，该参数为“None”就表示“GridSearchCV”与“cross_val_score”都会去调用“estimator”自己的“score”函数，我们也可以为“scoring”参数指定别的性能度量标准，他必须是一个可调用对象，sklearn.metric不仅为我们提供了一系列预定义的可调用对象，而且好支持自定义评估标准。</p> 
 <p>在交叉验证中使用预定义scoring参数：</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>#在交叉验证中使用预定义scoring参数</p> 
 <p>from sklearn import svm,datasets</p> 
 <p>from sklearn.model_selection import cross_val_score</p> 
 <p>iris=datasets.load_iris()</p> 
 <p>X,y=iris.data,iris.target</p> 
 <p>clf=svm.SVC(probability=True,random_state=0)</p> 
 <p>print(cross_val_score(clf,X,y,scoring="neg_log_loss"))</p> 
 <p>#结果[-0.0757138  -0.16816241 -0.07091847]</p> 
 <p>model=svm.SVC()</p> 
 <p>print(cross_val_score(model,X,y,scoring="wrong_choice"))</p> 
 <p>#结果：</p> 
 <p>ValueError: 'wrong_choice' is not a valid scoring value. Valid options are ['accuracy', 'adjusted_rand_score', 'average_precision', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_median_absolute_error', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc']</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>”scoring“的可用类型都存放在sklearn.metric.SCORES字典对象中</p> 
 <p>三、sklearn分类器评估指标总体概况</p> 
 <p>使用sklearn.metric包中的性能度量函数有：</p> 
 <p>分类器性能指标</p> 
 <p>回归器性能指标</p> 
 <p>聚类其性能指标</p> 
 <p>两两距离测度</p> 
 <p>分类器性能度量指标</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>总的来说，主要分为以下3类</p> 
 <p>精度-召回率-F度量：Precision-Recall-F_measures</p> 
 <p>损失函数：Loss Function</p> 
 <p>接收机操作曲线：ROC Curves</p> 
 <p>只限于二分类单标签分类问题的评估指标</p> 
 <p>matthews_corrcoef(y_true,y_pred[],...):计算二元分类中的Matthews相关系数(MCC)</p> 
 <p>precision_recall_curve(y_true,probas_pred)：在不同的概率阈值下计算precision-recall点，形成曲线</p> 
 <p>roc_curve(y_true,y_score[,pos_label,...]):计算ROC曲线</p> 
 <p>可用于二分类多标签分类问题的评估指标</p> 
 <p>average_precision_score(y_true,y_score[,...]) 计算预测得分的平均精度(mAP)</p> 
 <p>roc_auc_score(y_true,y_score[,average,...])计算预测得分的AUC值</p> 
 <p>可用于多分类问题的评估指标(紫色的可用于多标签分类问题)</p> 
 <p>cohen_kappa_score(y1,y2[,labels,weights])</p> 
 <p>confusion_matrix(y_true,y_pred[,labels,...])</p> 
 <p>hinge_loss(y_true,pred_decision[,labels,...])</p> 
 <p>accuracy_score(y_true,y_pred[,normalize,...])</p> 
 <p>classification_report(y_true,y_pred[,...])</p> 
 <p>f1_score(y_true,y_pres[,labels,...])</p> 
 <p>fbeta_score(y_true,,y_pres,beta[,labels,...])</p> 
 <p>hamming_loss(y_true,y_pres[,labels,...])</p> 
 <p>jaccard_similarity_score(y_true,y_pres[,...])</p> 
 <p>log_loss(y_true,y_pres[,eps,normalize,...])</p> 
 <p>zero_one_loss(y_true,y_pres[,normalize,...])</p> 
 <p>precision_recall_fsconfe_support(y_true,y_pres)</p> 
 <p>多分类性能评估指标</p> 
 <p>将二分类指标拓展到多分类或多标签问题中：</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>分类器性能评估指标：</p> 
 <p>接收机操作曲线Reciever Operating Curves-》可用于二分类问题</p> 
 <p>解卡德指数(相似性系数)Jaccard similarity coefficient-》可用于多分类问题</p> 
 <p>MCC指标(相关性系数)Matthews correlation coefficient-》可用于二分类问题</p> 
 <p>四、分类器评估标准</p> 
 <p>准确率：返回被正确分类的样本比例(default)或者数量(normalize=False)</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>#准确率</p> 
 <p>import numpy as np</p> 
 <p>from sklearn.metrics import accuracy_score</p> 
 <p>y_pred=[0,2,1,3]</p> 
 <p>y_true=[0,1,2,3]</p> 
 <p>print(accuracy_score(y_true,y_pred))</p> 
 <p>print(accuracy_score(y_true,y_pred,normalize=False))</p> 
 <p>#0.5</p> 
 <p>#2</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>混淆矩阵</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>from sklearn.metrics import confusion_matrix</p> 
 <p>y_true=[2,0,2,2,0,1]</p> 
 <p>y_pred=[0,0,2,2,0,2]</p> 
 <p>print(confusion_matrix(y_true,y_pred))</p> 
 <p>y_true=["cat","ant","cat","cat","ant","bird"]</p> 
 <p>y_pred=["ant","ant","cat","cat","ant","cat"]</p> 
 <p>print(confusion_matrix(y_true,y_pred,labels=["ant","cat","bird"]))</p> 
 <p>#[[2 0 0][0 0 1][1 0 2]]#[[2 0 0][1 2 0][0 1 0]]</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>二元分类问题：</p> 
 <p align="center"><img src="" alt=""></p> 
 <p align="center"><img src="" alt=""></p> 
 <p>#precision-recall-F-measures</p> 
 <p>from sklearn import metrics</p> 
 <p>y_pred=[0,1,0,0]</p> 
 <p>y_true=[0,1,0,1]</p> 
 <p>print(metrics.precision_score(y_true,y_pred))</p> 
 <p>#1.0</p> 
 <p>print(metrics.recall_score(y_true,y_pred))</p> 
 <p>#0.5</p> 
 <p>print(metrics.f1_score(y_true,y_pred))</p> 
 <p>#0.666666666667</p> 
 <p>print(metrics.fbeta_score(y_true,y_pred,beta=0.5))</p> 
 <p>#0.833333333333</p> 
 <p>print(metrics.fbeta_score(y_true,y_pred,beta=1))</p> 
 <p>#0.666666666667</p> 
 <p>print(metrics.fbeta_score(y_true,y_pred,beta=2))</p> 
 <p>#0.555555555556</p> 
 <p>print(metrics.precision_recall_fscore_support(y_true,y_pred,beta=0.5))</p> 
 <p>#(array([ 0.66666667, 1. ]), array([ 1. , 0.5]), array([ 0.71428571, 0.83333333]), array([2, 2], dtype=int32))</p> 
 <p>import numpy as np</p> 
 <p>from sklearn.metrics import precision_recall_curve</p> 
 <p>from sklearn.metrics import average_precision_score</p> 
 <p>y_true=np.array([0,0,1,1])</p> 
 <p>y_score=np.array([0.1,0.4,0.35,0.8])</p> 
 <p>precision,recall,threahold=precision_recall_curve(y_true,y_score)</p> 
 <p>print(precision)</p> 
 <p>#[ 0.66666667 0.5 1. 1. ]</p> 
 <p>print(recall)</p> 
 <p>[ 1. 0.5 0.5 0. ]</p> 
 <p>print(threahold)</p> 
 <p>#[ 0.35 0.4 0.8 ]</p> 
 <p>print(average_precision_score(y_true,y_score))</p> 
 <p>#0.791666666667</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>多类别多标签分类问题</p> 
 <p>把其中的一类看成是正类，其他所有类看成是负类，每一类都可以看作是正类是都可以产生P，R，F，此时，可以按照5中方式来组合每一个类的结果，这5种方式是：macro，weighted，micro，samples，average=None</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>from sklearn import metrics</p> 
 <p>y_true=[0,1,2,0,1,2]</p> 
 <p>y_pred=[0,2,1,0,0,1]</p> 
 <p>print(metrics.precision_score(y_true,y_pred,average="macro"))</p> 
 <p>#0.222222222222print(metrics.recall_score(y_true,y_pred,average="micro"))</p> 
 <p>#0.333333333333</p> 
 <p>print(metrics.f1_score(y_true,y_pred,average="weighted"))</p> 
 <p>#0.266666666667</p> 
 <p>print(metrics.fbeta_score(y_true,y_pred,average="macro",beta=0.5))</p> 
 <p>#0.238095238095</p> 
 <p>print(metrics.precision_recall_fscore_support(y_true,y_pred,beta=0.5,average="None"))</p> 
 <p>#(array([ 0.66666667, 0. , 0. ]), array([ 1., 0., 0.]), array([ 0.71428571, 0. , 0. ]), array([2, 2, 2], dtype=int32))</p> 
 <p>print(metrics.recall_score(y_true,y_pred,average="micro",labels=[1,2]))</p> 
 <p>#0.0</p> 
 <p align="center"><img src="" alt=""></p> 
 <p>from sklearn.metrics import classification_report</p> 
 <p>y_true=[0,1,2,0,1,2]</p> 
 <p>y_pred=[0,2,1,0,0,1]</p> 
 <p>target_names=["class0","class1","class2"]</p> 
 <p>print(classification_report(y_true,y_pred,target_names=target_names))</p> 
 <p>结果为：</p> 
 <p>precision recall f1-score support</p> 
 <p>class0 0.67 1.00 0.80 2</p> 
 <p>class1 0.00 0.00 0.00 2</p> 
 <p>class2 0.00 0.00 0.00 2</p> 
 <p>avg / total 0.22 0.33 0.27 6</p> 
 <p>Roc曲线</p> 
 <p>ROC曲线只需知道true positive rate(TPR)和false positive rate(FPR)，TPR，FPR被看作是分类器的某个参数的函数。</p> 
 <p>TPR定义了在全部的正样本中，分类器找到了多少个真真的正样本</p> 
 <p>FPR定义了在全部的负样本中，分类器把多少负样本错误的分为正样本</p> 
</div>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/c3acaeafb23fa4e2a4b51ddabbb74383/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">编译原理-正则文法与正则表达式的相互转化</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/e7eb7f71de55ea720ff91b668a1227bc/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">移动宽带套餐介绍_中国移动宽带套餐有哪些，谢谢！</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>