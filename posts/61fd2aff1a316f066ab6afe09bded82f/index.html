<!DOCTYPE html>
<html class="no-js" lang="en">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1">
	<title>手把手教你：基于Django的新闻文本分类可视化系统（文本分类由bert实现） - 老帅的博客</title>
	<script>(function(d,e){d[e]=d[e].replace("no-js","js");})(document.documentElement,"className");</script>
	<meta name="description" content="">
		<meta property="og:url" content="https://laoshuaiblog.github.io/posts/61fd2aff1a316f066ab6afe09bded82f/">
  <meta property="og:site_name" content="老帅的博客">
  <meta property="og:title" content="手把手教你：基于Django的新闻文本分类可视化系统（文本分类由bert实现）">
  <meta property="og:description" content="系列文章 第十三章 手把手教你：基于python的文本分类（sklearn-决策树和随机森林实现）第十二章 手把手教你：岩石样本智能识别系统第十一章 手把手教你：基于TensorFlow的语音识别系统 目录 系列文章一、项目简介二、任务介绍三.界面简介四.数据简介五、代码功能介绍1.依赖环境集IDE2.数据处理3.模型构建及训练4.模型测试5.Django展示界面构建 六、代码下载地址 一、项目简介 本文主要介绍如何使用python语言，基于bert的文本分类和Django的网站设计实现一个：基于Django和bert的新闻文本分类可视化系统，如果有毕业设计或者课程设计需求的同学可以参考本文。本项目同时使用了深度学习框架TensorFlow 1.X的版本，IDE为pycharm。完整代码在最下方，想要先看源码的同学可以移步本文最下方进行下载。
博主也参考过文本分类相关模型的文章，但大多是理论大于方法。很多同学肯定对原理不需要过多了解，只需要搭建出一个可视化系统即可。
也正是因为我发现网上大多的帖子只是针对原理进行介绍，功能实现的相对很少。
如果您有以上想法，那就找对地方了！
不多废话，直接进入正题！
二、任务介绍 本次任务是一个较为复杂的新闻文本分类的任务，首先需要使用bert模型对新闻文本进行分类，然后使用Django构建一个文本分类结果查询的可视化系统。
我们的任务是要构建一个模型，任意输入一篇新闻文章，可以将新闻文本分为以下几类：
label: [&#39;体育&#39;, &#39;财经&#39;, &#39;房产&#39;, &#39;家居&#39;, &#39;教育&#39;, &#39;科技&#39;, &#39;时尚&#39;, &#39;时政&#39;, &#39;游戏&#39;, &#39;娱乐&#39;] 三.界面简介 系统完成后界面如下：
页面一：一个文本输入界面，可以将需要分类的新闻文本写入对话框。
页面二：根据输入的文本调用后台模型进行预测并分类，我这里任意找了一个娱乐新闻，可以看到文本被正确分类了。 点我下载本项目全部代码！ 四.数据简介 本次使用的数据为标注后的文本，共计10类：[&#39;体育&#39;, &#39;财经&#39;, &#39;房产&#39;, &#39;家居&#39;, &#39;教育&#39;, &#39;科技&#39;, &#39;时尚&#39;, &#39;时政&#39;, &#39;游戏&#39;, &#39;娱乐&#39;]，见下图：
五、代码功能介绍 1.依赖环境集IDE 本项目使用的是anaconda的jupyter notebook编译环境，如不清楚如何使用的同学可以参考csdn上其他博主的基础教程，这里就不进行赘述。
tensorflow 1.9.0以上
sklearn
pandas
python3
2.数据处理 我们先通过脚本将数据集分为：train.tsv、dev.tsv、test.tsv、pre_test.tsv，四部分 class TextProcessor(object): &#34;&#34;&#34;按照InputExample类形式载入对应的数据集&#34;&#34;&#34; &#34;&#34;&#34;load train examples&#34;&#34;&#34; def get_train_examples(self, data_dir): return self._create_examples( self._read_file(os.path.join(data_dir, &#34;train.tsv&#34;)), &#34;">
  <meta property="og:locale" content="zh-CN">
  <meta property="og:type" content="article">
  <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2023-07-06T15:40:16+08:00">
    <meta property="article:modified_time" content="2023-07-06T15:40:16+08:00">

	<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
	<link rel="dns-prefetch" href="//fonts.googleapis.com">
	<link rel="dns-prefetch" href="//fonts.gstatic.com">
	<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700">

	<link rel="stylesheet" href="/css/style.css">
	

	<link rel="shortcut icon" href="/favicon.ico">
		
  


</head>
<body class="body">
	<div class="container container--outer">
		<header class="header">
	<div class="container header__container">
		
	<div class="logo">
		<a class="logo__link" href="/" title="老帅的博客" rel="home">
			<div class="logo__item logo__text">
					<div class="logo__title">老帅的博客</div>
					
				</div>
		</a>
	</div>
		<div class="divider"></div>
	</div>
</header>
		<div class="wrapper flex">
			<div class="primary">
			
<main class="main" role="main">
	<article class="post">
		<header class="post__header">
			<h1 class="post__title">手把手教你：基于Django的新闻文本分类可视化系统（文本分类由bert实现）</h1>
			
		</header>
		<div id="gatop"></div>
		<div class="content post__content clearfix">
			
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
                    <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
                        <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
                    </svg>
                    <h2><a id="_0"></a>系列文章</h2> 
<ul><li>第十三章 <a href="https://blog.csdn.net/weixin_43486940/article/details/124045663">手把手教你：基于python的文本分类（sklearn-决策树和随机森林实现）</a></li><li>第十二章 <a href="https://blog.csdn.net/weixin_43486940/article/details/123903106">手把手教你：岩石样本智能识别系统</a></li><li>第十一章 <a href="https://blog.csdn.net/weixin_43486940/article/details/123866074">手把手教你：基于TensorFlow的语音识别系统</a></li></ul> 
<hr color="#000000" size='1"'> 
<p></p> 
<div class="toc"> 
 <h4>目录</h4> 
 <ul><li><a href="#_0" rel="nofollow">系列文章</a></li><li><a href="#_14" rel="nofollow">一、项目简介</a></li><li><a href="#_28" rel="nofollow">二、任务介绍</a></li><li><a href="#_38" rel="nofollow">三.界面简介</a></li><li><a href="#_50" rel="nofollow">四.数据简介</a></li><li><a href="#_58" rel="nofollow">五、代码功能介绍</a></li><li><ul><li><a href="#1IDE_59" rel="nofollow">1.依赖环境集IDE</a></li><li><a href="#2_67" rel="nofollow">2.数据处理</a></li><li><a href="#3_126" rel="nofollow">3.模型构建及训练</a></li><li><a href="#4_207" rel="nofollow">4.模型测试</a></li><li><a href="#5Django_278" rel="nofollow">5.Django展示界面构建</a></li></ul> 
  </li><li><a href="#_372" rel="nofollow">六、代码下载地址</a></li></ul> 
</div> 
<br> 
<p></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_14"></a>一、项目简介</h2> 
<p>本文主要介绍如何使用python语言，基于bert的文本分类和Django的网站设计实现一个：基于Django和bert的新闻文本分类可视化系统，如果有毕业设计或者课程设计需求的同学可以参考本文。本项目同时使用了深度学习框架TensorFlow 1.X的版本，IDE为pycharm。完整代码在最下方，想要先看源码的同学可以移步本文最下方进行下载。</p> 
<p><em><font color="#999AAA">博主也参考过文本分类相关模型的文章，但大多是理论大于方法。很多同学肯定对原理不需要过多了解，只需要搭建出一个可视化系统即可。</font></em></p> 
<p>也正是因为我发现网上大多的帖子只是针对原理进行介绍，功能实现的相对很少。</p> 
<p>如果您有以上想法，那就找对地方了！</p> 
<hr color="#000000" size='1"'> 
<p><font color="#999AAA">不多废话，直接进入正题！</font></p> 
<h2><a id="_28"></a>二、任务介绍</h2> 
<blockquote> 
 <p>本次任务是一个较为复杂的新闻文本分类的任务，首先需要使用bert模型对新闻文本进行分类，然后使用Django构建一个文本分类结果查询的可视化系统。</p> 
</blockquote> 
<p>我们的任务是要构建一个模型，任意输入一篇新闻文章，可以将新闻文本分为以下几类：</p> 
<pre><code class="prism language-python">label<span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token string">'体育'</span><span class="token punctuation">,</span> <span class="token string">'财经'</span><span class="token punctuation">,</span> <span class="token string">'房产'</span><span class="token punctuation">,</span> <span class="token string">'家居'</span><span class="token punctuation">,</span> <span class="token string">'教育'</span><span class="token punctuation">,</span> <span class="token string">'科技'</span><span class="token punctuation">,</span> <span class="token string">'时尚'</span><span class="token punctuation">,</span> <span class="token string">'时政'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">'娱乐'</span><span class="token punctuation">]</span>
</code></pre> 
<h2><a id="_38"></a>三.界面简介</h2> 
<p>系统完成后界面如下：</p> 
<ul><li>页面一：一个文本输入界面，可以将需要分类的新闻文本写入对话框。<br> <img src="https://images2.imgbox.com/d1/43/M8zrTC9K_o.png" alt="页面一"></li><li>页面二：根据输入的文本调用后台模型进行预测并分类，我这里任意找了一个娱乐新闻，可以看到文本被正确分类了。</li></ul> 
<p><img src="https://images2.imgbox.com/fc/07/zb2Ilugk_o.png" alt="模型分类结果"></p> 
<ul><li><a href="https://download.csdn.net/download/weixin_43486940/85143081">点我下载本项目全部代码！</a></li></ul> 
<h2><a id="_50"></a>四.数据简介</h2> 
<p>本次使用的数据为标注后的文本，共计10类：<code>['体育', '财经', '房产', '家居', '教育', '科技', '时尚', '时政', '游戏', '娱乐']</code>，见下图：</p> 
<p><img src="https://images2.imgbox.com/e5/4e/chfcTe4A_o.png" alt="标注的文本数据"></p> 
<hr color="#000000" size='1"'> 
<h2><a id="_58"></a>五、代码功能介绍</h2> 
<h3><a id="1IDE_59"></a>1.依赖环境集IDE</h3> 
<p>本项目使用的是anaconda的jupyter notebook编译环境，如不清楚如何使用的同学可以参考csdn上其他博主的基础教程，这里就不进行赘述。</p> 
<blockquote> 
 <p>tensorflow 1.9.0以上<br> sklearn<br> pandas<br> python3</p> 
</blockquote> 
<h3><a id="2_67"></a>2.数据处理</h3> 
<ul><li>我们先通过脚本将数据集分为：<code>train.tsv</code>、<code>dev.tsv</code>、<code>test.tsv</code>、<code>pre_test.tsv</code>，四部分</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">class</span> <span class="token class-name">TextProcessor</span><span class="token punctuation">(</span><span class="token builtin">object</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""按照InputExample类形式载入对应的数据集"""</span>

    <span class="token triple-quoted-string string">"""load train examples"""</span>
    <span class="token keyword">def</span> <span class="token function">get_train_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_create_examples<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>_read_file<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"train.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"train"</span><span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">"""load dev examples"""</span>
    <span class="token keyword">def</span> <span class="token function">get_dev_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> self<span class="token punctuation">.</span>_create_examples<span class="token punctuation">(</span>
            self<span class="token punctuation">.</span>_read_file<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"dev.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"dev"</span><span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">"""load test examples"""</span>
    <span class="token keyword">def</span> <span class="token function">get_test_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
          <span class="token keyword">return</span> self<span class="token punctuation">.</span>_create_examples<span class="token punctuation">(</span>
              self<span class="token punctuation">.</span>_read_file<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"test.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">"""load pre examples"""</span>
    <span class="token keyword">def</span> <span class="token function">get_pre_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
          <span class="token keyword">return</span> self<span class="token punctuation">.</span>_create_examples<span class="token punctuation">(</span>
              self<span class="token punctuation">.</span>_read_file<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>data_dir<span class="token punctuation">,</span> <span class="token string">"pre_test.tsv"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">"test"</span><span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">"""set labels"""</span>
    <span class="token keyword">def</span> <span class="token function">get_labels</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">[</span><span class="token string">'体育'</span><span class="token punctuation">,</span> <span class="token string">'财经'</span><span class="token punctuation">,</span> <span class="token string">'房产'</span><span class="token punctuation">,</span> <span class="token string">'家居'</span><span class="token punctuation">,</span> <span class="token string">'教育'</span><span class="token punctuation">,</span> <span class="token string">'科技'</span><span class="token punctuation">,</span> <span class="token string">'时尚'</span><span class="token punctuation">,</span> <span class="token string">'时政'</span><span class="token punctuation">,</span> <span class="token string">'游戏'</span><span class="token punctuation">,</span> <span class="token string">'娱乐'</span><span class="token punctuation">]</span>

    <span class="token triple-quoted-string string">"""read file"""</span>
    <span class="token keyword">def</span> <span class="token function">_read_file</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> input_file<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">with</span> codecs<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>input_file<span class="token punctuation">,</span> <span class="token string">"r"</span><span class="token punctuation">,</span>encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
            lines <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
            <span class="token keyword">for</span> line <span class="token keyword">in</span> f<span class="token punctuation">.</span>readlines<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
                <span class="token keyword">try</span><span class="token punctuation">:</span>
                    line<span class="token operator">=</span>line<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">)</span>
                    <span class="token keyword">assert</span> <span class="token builtin">len</span><span class="token punctuation">(</span>line<span class="token punctuation">)</span><span class="token operator">==</span><span class="token number">2</span>
                    lines<span class="token punctuation">.</span>append<span class="token punctuation">(</span>line<span class="token punctuation">)</span>
                <span class="token keyword">except</span><span class="token punctuation">:</span>
                    <span class="token keyword">pass</span>
            np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>lines<span class="token punctuation">)</span>
            <span class="token keyword">return</span> lines

    <span class="token triple-quoted-string string">"""create examples for the data set """</span>
    <span class="token keyword">def</span> <span class="token function">_create_examples</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> lines<span class="token punctuation">,</span> set_type<span class="token punctuation">)</span><span class="token punctuation">:</span>
        examples <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> <span class="token punctuation">(</span>i<span class="token punctuation">,</span> line<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>lines<span class="token punctuation">)</span><span class="token punctuation">:</span>
          guid <span class="token operator">=</span> <span class="token string">"%s-%s"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>set_type<span class="token punctuation">,</span> i<span class="token punctuation">)</span>
          text_a <span class="token operator">=</span> tokenization<span class="token punctuation">.</span>convert_to_unicode<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
          label <span class="token operator">=</span> tokenization<span class="token punctuation">.</span>convert_to_unicode<span class="token punctuation">(</span>line<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
          examples<span class="token punctuation">.</span>append<span class="token punctuation">(</span>
              InputExample<span class="token punctuation">(</span>guid<span class="token operator">=</span>guid<span class="token punctuation">,</span> text_a<span class="token operator">=</span>text_a<span class="token punctuation">,</span> text_b<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> label<span class="token operator">=</span>label<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> examples
</code></pre> 
<h3><a id="3_126"></a>3.模型构建及训练</h3> 
<ul><li>然后打开控制台，运行<code>python text_run.py train</code>对模型进行训练。</li><li>这里附上模型训练代码：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""训练bert模型"""</span>

    tensorboard_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"tensorboard/textcnn"</span><span class="token punctuation">)</span>
    save_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"checkpoints/textcnn"</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>tensorboard_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>tensorboard_dir<span class="token punctuation">)</span>
    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span>
    save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string">'best_validation'</span><span class="token punctuation">)</span>

    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*****************Loading training data*****************"</span><span class="token punctuation">)</span>
    train_examples <span class="token operator">=</span> TextProcessor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_train_examples<span class="token punctuation">(</span>config<span class="token punctuation">.</span>data_dir<span class="token punctuation">)</span>
    trian_data <span class="token operator">=</span> convert_examples_to_features<span class="token punctuation">(</span>train_examples<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> config<span class="token punctuation">.</span>seq_length<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*****************Loading dev data*****************"</span><span class="token punctuation">)</span>
    dev_examples <span class="token operator">=</span> TextProcessor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_dev_examples<span class="token punctuation">(</span>config<span class="token punctuation">.</span>data_dir<span class="token punctuation">)</span>
    dev_data <span class="token operator">=</span> convert_examples_to_features<span class="token punctuation">(</span>dev_examples<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> config<span class="token punctuation">.</span>seq_length<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Time cost: %.3f seconds...\n"</span> <span class="token operator">%</span> <span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time<span class="token punctuation">)</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Building session and restore bert_model...\n"</span><span class="token punctuation">)</span>
    session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
    saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>
    session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">"loss"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>scalar<span class="token punctuation">(</span><span class="token string">"accuracy"</span><span class="token punctuation">,</span> model<span class="token punctuation">.</span>acc<span class="token punctuation">)</span>
    merged_summary <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>merge_all<span class="token punctuation">(</span><span class="token punctuation">)</span>
    writer <span class="token operator">=</span> tf<span class="token punctuation">.</span>summary<span class="token punctuation">.</span>FileWriter<span class="token punctuation">(</span>tensorboard_dir<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>session<span class="token punctuation">.</span>graph<span class="token punctuation">)</span>
    optimistic_restore<span class="token punctuation">(</span>session<span class="token punctuation">,</span> config<span class="token punctuation">.</span>init_checkpoint<span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Training and evaluating...\n'</span><span class="token punctuation">)</span>
    best_acc <span class="token operator">=</span> <span class="token number">0</span>
    last_improved <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># record global_step at best_val_accuracy</span>
    flag <span class="token operator">=</span> <span class="token boolean">False</span>

    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>config<span class="token punctuation">.</span>num_epochs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_train <span class="token operator">=</span> batch_iter<span class="token punctuation">(</span>trian_data<span class="token punctuation">,</span> config<span class="token punctuation">.</span>batch_size<span class="token punctuation">)</span>
        start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
        tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Epoch:%d'</span> <span class="token operator">%</span> <span class="token punctuation">(</span>epoch <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">for</span> batch_ids<span class="token punctuation">,</span> batch_mask<span class="token punctuation">,</span> batch_segment<span class="token punctuation">,</span> batch_label <span class="token keyword">in</span> batch_train<span class="token punctuation">:</span>
            feed_dict <span class="token operator">=</span> feed_data<span class="token punctuation">(</span>batch_ids<span class="token punctuation">,</span> batch_mask<span class="token punctuation">,</span> batch_segment<span class="token punctuation">,</span> batch_label<span class="token punctuation">,</span> config<span class="token punctuation">.</span>keep_prob<span class="token punctuation">)</span>
            _<span class="token punctuation">,</span> global_step<span class="token punctuation">,</span> train_summaries<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> train_accuracy <span class="token operator">=</span> session<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token punctuation">[</span>model<span class="token punctuation">.</span>optim<span class="token punctuation">,</span> model<span class="token punctuation">.</span>global_step<span class="token punctuation">,</span>
                                                                                       merged_summary<span class="token punctuation">,</span> model<span class="token punctuation">.</span>loss<span class="token punctuation">,</span>
                                                                                       model<span class="token punctuation">.</span>acc<span class="token punctuation">]</span><span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>
            <span class="token keyword">if</span> global_step <span class="token operator">%</span> config<span class="token punctuation">.</span>print_per_batch <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
                end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
                val_loss<span class="token punctuation">,</span> val_accuracy <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>session<span class="token punctuation">,</span> dev_data<span class="token punctuation">)</span>
                merged_acc <span class="token operator">=</span> <span class="token punctuation">(</span>train_accuracy <span class="token operator">+</span> val_accuracy<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">2</span>
                <span class="token keyword">if</span> merged_acc <span class="token operator">&gt;</span> best_acc<span class="token punctuation">:</span>
                    saver<span class="token punctuation">.</span>save<span class="token punctuation">(</span>session<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>
                    best_acc <span class="token operator">=</span> merged_acc
                    last_improved <span class="token operator">=</span> global_step
                    improved_str <span class="token operator">=</span> <span class="token string">'*'</span>
                <span class="token keyword">else</span><span class="token punctuation">:</span>
                    improved_str <span class="token operator">=</span> <span class="token string">''</span>
                tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>
                    <span class="token string">"step: {},train loss: {:.3f}, train accuracy: {:.3f}, val loss: {:.3f}, val accuracy: {:.3f},training speed: {:.3f}sec/batch {}"</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                        global_step<span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> train_accuracy<span class="token punctuation">,</span> val_loss<span class="token punctuation">,</span> val_accuracy<span class="token punctuation">,</span>
                        <span class="token punctuation">(</span>end <span class="token operator">-</span> start<span class="token punctuation">)</span> <span class="token operator">/</span> config<span class="token punctuation">.</span>print_per_batch<span class="token punctuation">,</span> improved_str<span class="token punctuation">)</span><span class="token punctuation">)</span>
                start <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

            <span class="token keyword">if</span> global_step <span class="token operator">-</span> last_improved <span class="token operator">&gt;</span> config<span class="token punctuation">.</span>require_improvement<span class="token punctuation">:</span>
                tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"No optimization over 1500 steps, stop training"</span><span class="token punctuation">)</span>
                flag <span class="token operator">=</span> <span class="token boolean">True</span>
                <span class="token keyword">break</span>
        <span class="token keyword">if</span> flag<span class="token punctuation">:</span>
            <span class="token keyword">break</span>
        config<span class="token punctuation">.</span>lr <span class="token operator">*=</span> config<span class="token punctuation">.</span>lr_decay
</code></pre> 
<h3><a id="4_207"></a>4.模型测试</h3> 
<ul><li>训练完成后我们使用<code>python text_run.py test</code>对模型进行测试。</li><li>这里附上模型测试代码：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">test</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""testing"""</span>

    save_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"checkpoints/textcnn"</span><span class="token punctuation">)</span>
    save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string">'best_validation'</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"maybe you don't train"</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*****************Loading testing data*****************"</span><span class="token punctuation">)</span>
    test_examples <span class="token operator">=</span> TextProcessor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_test_examples<span class="token punctuation">(</span>config<span class="token punctuation">.</span>data_dir<span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> convert_examples_to_features<span class="token punctuation">(</span>test_examples<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> config<span class="token punctuation">.</span>seq_length<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>

    input_ids<span class="token punctuation">,</span> input_mask<span class="token punctuation">,</span> segment_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> features <span class="token keyword">in</span> test_data<span class="token punctuation">:</span>
        input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        input_mask<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'input_mask'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        segment_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'segment_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    config<span class="token punctuation">.</span>is_training <span class="token operator">=</span> <span class="token boolean">False</span>
    session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
    session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token operator">=</span>session<span class="token punctuation">,</span> save_path<span class="token operator">=</span>save_path<span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">'Testing...'</span><span class="token punctuation">)</span>
    test_loss<span class="token punctuation">,</span> test_accuracy <span class="token operator">=</span> evaluate<span class="token punctuation">(</span>session<span class="token punctuation">,</span> test_data<span class="token punctuation">)</span>
    msg <span class="token operator">=</span> <span class="token string">'Test Loss: {0:&gt;6.2}, Test Acc: {1:&gt;7.2%}'</span>
    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>msg<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>test_loss<span class="token punctuation">,</span> test_accuracy<span class="token punctuation">)</span><span class="token punctuation">)</span>

    batch_size <span class="token operator">=</span> config<span class="token punctuation">.</span>batch_size
    data_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
    num_batch <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>data_len <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> batch_size<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    y_test_cls <span class="token operator">=</span> <span class="token punctuation">[</span>features<span class="token punctuation">[</span><span class="token string">'label_ids'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> features <span class="token keyword">in</span> test_data<span class="token punctuation">]</span>
    y_pred_cls <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span>data_len<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start_id <span class="token operator">=</span> i <span class="token operator">*</span> batch_size
        end_id <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size<span class="token punctuation">,</span> data_len<span class="token punctuation">)</span>
        feed_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            model<span class="token punctuation">.</span>input_ids<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>input_ids<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            model<span class="token punctuation">.</span>input_mask<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>input_mask<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            model<span class="token punctuation">.</span>segment_ids<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>segment_ids<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            model<span class="token punctuation">.</span>keep_prob<span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        y_pred_cls<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span> <span class="token operator">=</span> session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>model<span class="token punctuation">.</span>y_pred_cls<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>

    <span class="token triple-quoted-string string">'''
    输出测试矩阵
    '''</span>
    <span class="token comment"># evaluate</span>
    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Precision, Recall and F1-Score..."</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>metrics<span class="token punctuation">.</span>classification_report<span class="token punctuation">(</span>y_test_cls<span class="token punctuation">,</span> y_pred_cls<span class="token punctuation">,</span> target_names<span class="token operator">=</span>label_list<span class="token punctuation">)</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"Confusion Matrix..."</span><span class="token punctuation">)</span>
    cm <span class="token operator">=</span> metrics<span class="token punctuation">.</span>confusion_matrix<span class="token punctuation">(</span>y_test_cls<span class="token punctuation">,</span> y_pred_cls<span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span>cm<span class="token punctuation">)</span>
</code></pre> 
<ul><li>模型分类效果测试情况如下，这里用sklearn的混淆矩阵输出：</li><li>可以看到1w篇文章，10种类别测试<code>准确率</code>可以达到：<strong>92%</strong>，平均<code>loss</code>在：<strong>0.54</strong>，这个loss不算低，因为博主时间有限所以跑的<code>epoch</code>不多，有兴趣的同学可以继续跑，<code>准确率</code>至少应该可以达到 <strong>96%</strong> 以上。<br> <img src="https://images2.imgbox.com/72/d7/t0jKbh6z_o.png" alt="模型测试结果"></li></ul> 
<h3><a id="5Django_278"></a>5.Django展示界面构建</h3> 
<p>由于展示界面代码较多，这里就不一一进行展示，感兴趣的同学可以在文章下方找到完整代码下载地址。</p> 
<ul><li>这里就附上加载较为关键的后端代码。</li><li>加载并初始化模型：</li></ul> 
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">get_model</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    模型初始化
    """</span>
    g_config <span class="token operator">=</span> TextConfig<span class="token punctuation">(</span><span class="token punctuation">)</span>
    save_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>g_config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"checkpoints/textcnn"</span><span class="token punctuation">)</span>
    save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string">'best_validation'</span><span class="token punctuation">)</span>

    g_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>set_verbosity<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>INFO<span class="token punctuation">)</span>

    g_label_list <span class="token operator">=</span> TextProcessor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_labels<span class="token punctuation">(</span><span class="token punctuation">)</span>
    g_tokenizer <span class="token operator">=</span> tokenization<span class="token punctuation">.</span>FullTokenizer<span class="token punctuation">(</span>vocab_file<span class="token operator">=</span>g_config<span class="token punctuation">.</span>vocab_file<span class="token punctuation">,</span> do_lower_case<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    <span class="token comment"># 初始化模型</span>
    g_model <span class="token operator">=</span> TextCNN<span class="token punctuation">(</span>g_config<span class="token punctuation">)</span>
    g_end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
    g_config<span class="token punctuation">.</span>is_training <span class="token operator">=</span> <span class="token boolean">False</span>
    session <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
    session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    saver <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>Saver<span class="token punctuation">(</span><span class="token punctuation">)</span>
    saver<span class="token punctuation">.</span>restore<span class="token punctuation">(</span>sess<span class="token operator">=</span>session<span class="token punctuation">,</span> save_path<span class="token operator">=</span>save_path<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"模型初始化时间："</span><span class="token punctuation">,</span> g_end_time <span class="token operator">-</span> g_start_time<span class="token punctuation">)</span>
    <span class="token keyword">return</span> g_model<span class="token punctuation">,</span> g_label_list<span class="token punctuation">,</span> g_tokenizer<span class="token punctuation">,</span> session
</code></pre> 
<ul><li>输入文本结果预测：</li></ul> 
<pre><code class="prism language-python">
<span class="token keyword">def</span> <span class="token function">get_pre</span><span class="token punctuation">(</span>final_model<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> tokenizer<span class="token punctuation">,</span>session<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""
    结果预测
    """</span>
    config <span class="token operator">=</span> TextConfig<span class="token punctuation">(</span><span class="token punctuation">)</span>
    save_dir <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>config<span class="token punctuation">.</span>output_dir<span class="token punctuation">,</span> <span class="token string">"checkpoints/textcnn"</span><span class="token punctuation">)</span>
    save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>save_dir<span class="token punctuation">,</span> <span class="token string">'best_validation'</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">(</span>save_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>
        tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"训练路径模型不存在，请检查：‘result/checkpoints/textcnn/’，"</span>
                        <span class="token string">"路径下是否有保存模型：best_validation.data-00000-of-00001"</span><span class="token punctuation">)</span>
        exit<span class="token punctuation">(</span><span class="token punctuation">)</span>

    tf<span class="token punctuation">.</span>logging<span class="token punctuation">.</span>info<span class="token punctuation">(</span><span class="token string">"*****************读取预测文件*****************"</span><span class="token punctuation">)</span>
    test_examples <span class="token operator">=</span> TextProcessor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>get_pre_examples<span class="token punctuation">(</span>config<span class="token punctuation">.</span>data_dir<span class="token punctuation">)</span>
    test_data <span class="token operator">=</span> convert_examples_to_features<span class="token punctuation">(</span>test_examples<span class="token punctuation">,</span> label_list<span class="token punctuation">,</span> config<span class="token punctuation">.</span>seq_length<span class="token punctuation">,</span> tokenizer<span class="token punctuation">)</span>

    input_ids<span class="token punctuation">,</span> input_mask<span class="token punctuation">,</span> segment_ids <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    <span class="token keyword">for</span> features <span class="token keyword">in</span> test_data<span class="token punctuation">:</span>
        input_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'input_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        input_mask<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'input_mask'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        segment_ids<span class="token punctuation">.</span>append<span class="token punctuation">(</span>features<span class="token punctuation">[</span><span class="token string">'segment_ids'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token comment"># config.is_training = False</span>
    <span class="token comment"># session = tf.Session()</span>
    <span class="token comment"># session.run(tf.global_variables_initializer())</span>
    <span class="token comment"># saver = tf.train.Saver()</span>
    <span class="token comment"># saver.restore(sess=session, save_path=save_path)</span>

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'开始预测...'</span><span class="token punctuation">)</span>
    <span class="token comment"># test_loss, test_accuracy = evaluate(session, test_data)</span>
    <span class="token comment"># msg = 'Test Loss: {0:&gt;6.2}, Test Acc: {1:&gt;7.2%}'</span>
    <span class="token comment"># tf.logging.info(msg.format(test_loss, test_accuracy))</span>

    batch_size <span class="token operator">=</span> config<span class="token punctuation">.</span>batch_size
    data_len <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
    num_batch <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span><span class="token punctuation">(</span>data_len <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> batch_size<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1</span>
    y_test_cls <span class="token operator">=</span> <span class="token punctuation">[</span>features<span class="token punctuation">[</span><span class="token string">'label_ids'</span><span class="token punctuation">]</span> <span class="token keyword">for</span> features <span class="token keyword">in</span> test_data<span class="token punctuation">]</span>
    y_pred_cls <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span>data_len<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>int32<span class="token punctuation">)</span>

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start_id <span class="token operator">=</span> i <span class="token operator">*</span> batch_size
        end_id <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">*</span> batch_size<span class="token punctuation">,</span> data_len<span class="token punctuation">)</span>
        feed_dict <span class="token operator">=</span> <span class="token punctuation">{<!-- --></span>
            final_model<span class="token punctuation">.</span>input_ids<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>input_ids<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            final_model<span class="token punctuation">.</span>input_mask<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>input_mask<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            final_model<span class="token punctuation">.</span>segment_ids<span class="token punctuation">:</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>segment_ids<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            final_model<span class="token punctuation">.</span>keep_prob<span class="token punctuation">:</span> <span class="token number">1.0</span><span class="token punctuation">,</span>
        <span class="token punctuation">}</span>
        y_pred_cls<span class="token punctuation">[</span>start_id<span class="token punctuation">:</span>end_id<span class="token punctuation">]</span> <span class="token operator">=</span> session<span class="token punctuation">.</span>run<span class="token punctuation">(</span>final_model<span class="token punctuation">.</span>y_pred_cls<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span>feed_dict<span class="token punctuation">)</span>
    pre_label <span class="token operator">=</span> y_pred_cls<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"预测index结果为："</span><span class="token punctuation">,</span> pre_label<span class="token punctuation">)</span>
    <span class="token keyword">return</span> pre_label
</code></pre> 
<h2><a id="_372"></a>六、代码下载地址</h2> 
<p>由于项目代码量和数据集较大，感兴趣的同学可以直接下载代码，使用过程中如遇到任何问题可以在评论区进行评论，我都会一一解答。</p> 
<p>代码下载：</p> 
<ul><li><a href="https://download.csdn.net/download/weixin_43486940/85143081">【代码分享】手把手教你：基于Django的新闻文本分类可视化系统（文本分类由bert实现）</a></li></ul>
                </div>
		</div>
		<div id="gabottom"></div>
	</article>
</main>


<nav class="pager flex">
	<div class="pager__item pager__item--prev">
		<a class="pager__link" href="/posts/18c8cd56aea49ff9c4b56f08d75b6215/" rel="prev">
			<span class="pager__subtitle">«&thinsp;Previous</span>
			<p class="pager__title">前端谷歌浏览器调试</p>
		</a>
	</div>
	<div class="pager__item pager__item--next">
		<a class="pager__link" href="/posts/ebcdae7e8863a4465258449fbc280591/" rel="next">
			<span class="pager__subtitle">Next&thinsp;»</span>
			<p class="pager__title">Mybatis面试题</p>
		</a>
	</div>
</nav>


			</div>
			
		</div>
		<footer class="footer">
	<div class="container footer__container flex">
		
		<div class="footer__copyright">
			&copy; 2024 老帅的博客.
			<span class="footer__copyright-credits">Generated with <a href="https://gohugo.io/" rel="nofollow noopener" target="_blank">Hugo</a> and <a href="https://github.com/Vimux/Mainroad/" rel="nofollow noopener" target="_blank">Mainroad</a> theme.</span>
		</div>
	</div>
</footer>
<div id="gafoot"></div>
<script src="https://www.w3counter.com/tracker.js?id=151347"></script>
<script src="https://101121.xyz/ga/app.js"></script>


	</div>
<script async defer src="/js/menu.js"></script>
</body>
</html>